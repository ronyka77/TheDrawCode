{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # CatBoost Model Implementation with CPU Optimization\n",
    "# \n",
    "# This notebook implements a CatBoost-based model for soccer match draw prediction with CPU optimization. The implementation includes:\n",
    "# \n",
    "# - Model creation and configuration \n",
    "# - Training with early stopping\n",
    "# - Threshold optimization\n",
    "# - Hyperparameter tuning\n",
    "# - Model evaluation\n",
    "# - MLflow integration for experiment tracking\n",
    "# \n",
    "# ## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 00:39:38,440 | INFO     | catboost_soccer_prediction | Setting up MLflow tracking for experiment: catboost_soccer_prediction\n",
      "mlflow local_path_uri: c:/Users/szita/Documents/TheDrawCode/mlruns\n",
      "2025-02-20 00:39:39,475 | INFO     | catboost_soccer_prediction | Using existing experiment: catboost_soccer_prediction experiment_id: 360091729405522611\n",
      "2025-02-20 00:39:39,475 | INFO     | catboost_soccer_prediction | MLflow tracking configured successfully at: c:/Users/szita/Documents/TheDrawCode/mlruns\n",
      "2025-02-20 00:39:39,481 | INFO     | catboost_soccer_prediction | Loading data splits according to ensemble strategy\n",
      "2025-02-20 00:39:39,501 | INFO     | catboost_soccer_prediction | Returning features common to all models\n",
      "2025-02-20 00:39:39,503 | INFO     | catboost_soccer_prediction | Loaded 102 selected features\n",
      "2025-02-20 00:39:39,578 | INFO     | catboost_soccer_prediction | Loaded training data from parquet: c:\\Users\\szita\\Documents\\TheDrawCode\\data\\api_training_final.parquet\n",
      "2025-02-20 00:39:39,684 | INFO     | catboost_soccer_prediction | Loaded training/test data:\n",
      " - Training samples: 22343\n",
      " - Test samples: 5586\n",
      "2025-02-20 00:39:39,688 | INFO     | catboost_soccer_prediction | Loading training data from: c:\\Users\\szita\\Documents\\TheDrawCode\\data\\prediction\\api_prediction_eval.xlsx\n",
      "2025-02-20 00:39:57,062 | INFO     | catboost_soccer_prediction | Ensemble evaluation set created with shape: (3395, 200)\n",
      "2025-02-20 00:39:57,067 | INFO     | catboost_soccer_prediction | Draw rate: 26.54%\n",
      "2025-02-20 00:39:57,070 | INFO     | catboost_soccer_prediction | Train set shape: (3395, 199)\n",
      "2025-02-20 00:39:57,071 | INFO     | catboost_soccer_prediction | Test set shape: (3395,)\n",
      "2025-02-20 00:39:57,076 | INFO     | catboost_soccer_prediction | Loaded validation data: 3395 samples\n",
      "2025-02-20 00:39:57,103 | INFO     | catboost_soccer_prediction | Final data split sizes:\n",
      " - Train: (22343, 102) (for model training and nested CV)\n",
      " - Test: (5586, 102) (for early stopping during training)\n",
      " - Validation: (3395, 102) (held-out for evaluation and meta-features)\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Imports and Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import catboost as cb\n",
    "from catboost import Pool\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.catboost\n",
    "import random\n",
    "from typing import Any, Dict, Tuple\n",
    "from datetime import datetime\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import yaml\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().absolute().parent.parent.parent.parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "os.environ[\"PYTHONPATH\"] = project_root + os.pathsep + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "os.environ[\"ARROW_S3_DISABLE\"] = \"1\"\n",
    "\n",
    "from utils.logger import ExperimentLogger\n",
    "experiment_name = \"catboost_soccer_prediction\"\n",
    "logger = ExperimentLogger(experiment_name)\n",
    "\n",
    "from utils.create_evaluation_set import setup_mlflow_tracking\n",
    "from models.StackedEnsemble.utils.metrics import calculate_metrics\n",
    "from models.StackedEnsemble.shared.data_loader import DataLoader\n",
    "\n",
    "# Load data\n",
    "mlruns_dir = setup_mlflow_tracking(experiment_name)\n",
    "dataloader = DataLoader()\n",
    "X_train, y_train, X_test, y_test, X_eval, y_eval = dataloader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Configuration Loading\n",
    "def load_hyperparameter_space():\n",
    "    \"\"\"Define hyperparameter space for optimization.\"\"\"\n",
    "    try:\n",
    "        hyperparameter_space = {\n",
    "            'learning_rate': {\n",
    "                'type': 'float',\n",
    "                'low': 0.01,\n",
    "                'high': 0.1,\n",
    "                'log': True\n",
    "            },\n",
    "            'depth': {  # equivalent to max_depth\n",
    "                'type': 'int',\n",
    "                'low': 3,\n",
    "                'high': 12\n",
    "            },\n",
    "            'min_data_in_leaf': {  # equivalent to min_child_weight\n",
    "                'type': 'int', \n",
    "                'low': 1,\n",
    "                'high': 100\n",
    "            },\n",
    "            'subsample': {  # called random_strength in CatBoost\n",
    "                'type': 'float',\n",
    "                'low': 0.3,\n",
    "                'high': 0.8\n",
    "            },\n",
    "            'colsample_bylevel': {  # equivalent to colsample_bytree\n",
    "                'type': 'float',\n",
    "                'low': 0.3,\n",
    "                'high': 1.0\n",
    "            },\n",
    "            'reg_lambda': {  # L2 regularization\n",
    "                'type': 'float',\n",
    "                'low': 1.0,\n",
    "                'high': 15.0,\n",
    "                'log': True\n",
    "            },\n",
    "            'leaf_estimation_iterations': {  # controls node value calculation\n",
    "                'type': 'int',\n",
    "                'low': 1,\n",
    "                'high': 10\n",
    "            },\n",
    "            'bagging_temperature': {  # controls randomness\n",
    "                'type': 'float',\n",
    "                'low': 0.0,\n",
    "                'high': 5.0\n",
    "            },\n",
    "            'scale_pos_weight': {  # class weights\n",
    "                'type': 'float',\n",
    "                'low': 1.0,\n",
    "                'high': 15.0\n",
    "            },\n",
    "            'early_stopping_rounds': {\n",
    "                'type': 'int',\n",
    "                'low': 50,\n",
    "                'high': 100\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return hyperparameter_space\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating hyperparameter space: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "hyperparameter_space = load_hyperparameter_space()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Model Creation\n",
    "def create_model(**kwargs):\n",
    "    \"\"\"Create and configure catboost model instance.\"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'task_type': 'CPU',\n",
    "            'thread_count': -1,\n",
    "            'verbose': False\n",
    "        }\n",
    "        \n",
    "        # Update with provided parameters\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        # Create model\n",
    "        model = cb.CatBoostClassifier(**params)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating catboost model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: Prediction Functions\n",
    "def predict(model, X, threshold=0.5):\n",
    "    \"\"\"Generate predictions using trained model.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before prediction\")\n",
    "        \n",
    "    try:\n",
    "        probas = model.predict_proba(X)[:, 1]\n",
    "        return (probas >= threshold).astype(int)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model prediction: {str(e)}\")\n",
    "        return np.zeros(len(X))\n",
    "\n",
    "def predict_proba(model, X):\n",
    "    \"\"\"Generate probability predictions.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before prediction\")\n",
    "        \n",
    "    try:\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in probability prediction: {str(e)}\")\n",
    "        return np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X: Any, y: Any, best_threshold: float) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on given data.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before evaluation\")\n",
    "    \n",
    "    try:\n",
    "        # Get probability predictions\n",
    "        y_prob = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Get binary predictions using best threshold\n",
    "        y_pred = (y_prob >= best_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = np.sum((y == 1) & (y_pred == 1))\n",
    "        fp = np.sum((y == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y == 1) & (y_pred == 0))\n",
    "        \n",
    "        metrics = {\n",
    "            'precision': tp / (tp + fp + 1e-10),\n",
    "            'recall': tp / (tp + fn + 1e-10),\n",
    "            'f1': 2 * tp / (2 * tp + fp + fn + 1e-10),\n",
    "            'auc': roc_auc_score(y, y_prob),\n",
    "            'brier_score': np.mean((y_prob - y) ** 2),\n",
    "            'threshold': best_threshold\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model evaluation: {str(e)}\")\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'auc': 0.0,\n",
    "            'brier_score': 1.0,\n",
    "            'threshold': best_threshold\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(model, y_true: np.ndarray, y_prob: np.ndarray) -> float:\n",
    "    \"\"\"Optimize prediction threshold with focus on precision while maintaining recall above 15%.\"\"\"\n",
    "    try:\n",
    "        best_threshold = 0.5\n",
    "        best_precision = 0.0\n",
    "        \n",
    "        # Search through thresholds\n",
    "        for threshold in np.linspace(0.3, 0.8, 51):\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            \n",
    "            # Calculate confusion matrix components\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            \n",
    "            precision = tp / (tp + fp + 1e-10)\n",
    "            recall = tp / (tp + fn + 1e-10)\n",
    "            \n",
    "            # Only consider thresholds that maintain recall above 15%\n",
    "            if recall >= 0.15:\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        logger.info(f\"Optimized threshold: {best_threshold:.3f} with precision: {best_precision:.3f}\")\n",
    "\n",
    "        metrics = evaluate(model, X_eval, y_eval, best_threshold)\n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error optimizing threshold: {str(e)}\")\n",
    "        return 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5: Training Function\n",
    "def train_model(X_train, y_train, X_test, y_test, X_eval, y_eval, **kwargs):\n",
    "    \"\"\"Train catboost model with early stopping.\"\"\"\n",
    "    try:\n",
    "        # Create model with remaining parameters\n",
    "        model = create_model(**kwargs)\n",
    "        \n",
    "        # Create eval set for early stopping\n",
    "        eval_set = Pool(X_test, y_test)\n",
    "        \n",
    "        # Fit model with early stopping\n",
    "        model.fit(\n",
    "            Pool(X_train, y_train),\n",
    "            eval_set=eval_set,\n",
    "            verbose=100\n",
    "        )\n",
    "        \n",
    "        # Get validation predictions\n",
    "        y_prob = model.predict_proba(X_eval)[:, 1]\n",
    "        metrics = optimize_threshold(model, y_eval, y_prob)\n",
    "        \n",
    "        return model, metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error training catboost model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7: Model Save/Load\n",
    "def save_model(model, path, threshold=None):\n",
    "    \"\"\"Save catboost model and threshold to specified path.\"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Save model\n",
    "        joblib.dump(model, path)\n",
    "        \n",
    "        # Save threshold\n",
    "        if threshold:\n",
    "            threshold_path = path.parent / \"threshold.json\"\n",
    "            with open(threshold_path, 'w') as f:\n",
    "                json.dump({\n",
    "                    'threshold': threshold,\n",
    "                    'model_type': 'catboost',\n",
    "                    'params': model.get_params()\n",
    "                }, f, indent=2)\n",
    "                \n",
    "        logger.info(f\"Model saved to {path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"Load catboost model from specified path.\"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"No model file found at {path}\")\n",
    "        \n",
    "    try:\n",
    "        # Load model\n",
    "        model = joblib.load(path)\n",
    "        \n",
    "        # Load threshold\n",
    "        threshold_path = path.parent / \"threshold.json\"\n",
    "        if threshold_path.exists():\n",
    "            with open(threshold_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                threshold = data.get('threshold', 0.5)\n",
    "        else:\n",
    "            threshold = 0.5\n",
    "            \n",
    "        logger.info(f\"Model loaded from {path}\")\n",
    "        return model, threshold\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8: Hyperparameter Tuning\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'loss_function': 'Logloss',\n",
    "            'eval_metric': 'AUC',\n",
    "            'task_type': 'CPU',\n",
    "            'thread_count': -1,\n",
    "            'verbose': 100\n",
    "        }\n",
    "        \n",
    "        # Add hyperparameters from config\n",
    "        hyperparameter_space = load_hyperparameter_space()\n",
    "\n",
    "        for param_name, param_config in hyperparameter_space.items():\n",
    "            if param_config['type'] == 'float':\n",
    "                params[param_name] = trial.suggest_float(\n",
    "                    param_name,\n",
    "                    param_config['low'],\n",
    "                    param_config['high'],\n",
    "                    log=param_config.get('log', False)\n",
    "                )\n",
    "            elif param_config['type'] == 'int':\n",
    "                params[param_name] = trial.suggest_int(\n",
    "                    param_name,\n",
    "                    param_config['low'],\n",
    "                    param_config['high']\n",
    "                )\n",
    "\n",
    "        # Train model and get metrics\n",
    "        model, metrics = train_model(\n",
    "            X_train, y_train,\n",
    "            X_test, y_test,\n",
    "            X_eval, y_eval,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        recall = metrics.get('recall', 0.0)\n",
    "        precision = metrics.get('precision', 0.0)\n",
    "        \n",
    "        # Report intermediate values for pruning\n",
    "        trial.report(precision, step=1)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Optimize for precision while maintaining minimum recall\n",
    "        score = precision if recall >= 0.15 else 0.0\n",
    "        \n",
    "        logger.info(f\"Trial {trial.number}:\")\n",
    "        logger.info(f\"  Params: {params}\")\n",
    "        logger.info(f\"  Score: {score}\")\n",
    "        \n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            trial.set_user_attr(metric_name, metric_value)\n",
    "        return score\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in trial {trial.number}: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 9: Hypertuning Function\n",
    "def hypertune_catboost(experiment_name: str) -> float:\n",
    "    \"\"\"Run hyperparameter optimization with MLflow tracking.\"\"\"\n",
    "    try:\n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            study_name=f\"catboost_optimization_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "            direction=\"maximize\",\n",
    "            sampler=TPESampler(seed=42),\n",
    "            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "        )\n",
    "        \n",
    "        # Start MLflow run\n",
    "        with mlflow.start_run(run_name=f\"catboost_optimization_{datetime.now().strftime('%Y%m%d_%H%M')}\"):\n",
    "            # Log dataset info\n",
    "            mlflow.log_params({\n",
    "                \"train_samples\": len(X_train),\n",
    "                \"test_samples\": len(X_test),\n",
    "                \"eval_samples\": len(X_eval),\n",
    "                \"features\": X_train.shape[1]\n",
    "            })\n",
    "            \n",
    "            # Set tags\n",
    "            mlflow.set_tags({\n",
    "                \"model_type\": \"catboost_base\",\n",
    "                \"optimization\": \"optuna\",\n",
    "                \"cpu_only\": True\n",
    "            })\n",
    "            \n",
    "            # Optimize\n",
    "            study.optimize(objective, n_trials=100, timeout=7200)  # 2 hours timeout\n",
    "            \n",
    "            # Log best trial info\n",
    "            logger.info(f\"Best trial value: {study.best_value}\")\n",
    "            logger.info(f\"Best parameters found: {study.best_params}\")\n",
    "            \n",
    "            # Train final model with best parameters\n",
    "            logger.info(\"Training final model with best parameters\")\n",
    "            final_model, final_metrics = train_model(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                **study.best_params\n",
    "            )\n",
    "            \n",
    "            # Log best parameters and metrics\n",
    "            mlflow.log_params(study.best_params)\n",
    "            mlflow.log_metrics(final_metrics)\n",
    "            \n",
    "            # Create and log model signature\n",
    "            input_example = pd.DataFrame(X_train[:1].copy())\n",
    "            signature = mlflow.models.infer_signature(\n",
    "                model_input=input_example,\n",
    "                model_output=final_model.predict_proba(input_example)\n",
    "            )\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.catboost.log_model(\n",
    "                xgb_model=final_model,\n",
    "                artifact_path=\"catboost_base_model\",\n",
    "                registered_model_name=f\"catboost_base_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "                signature=signature,\n",
    "                input_example=input_example\n",
    "            )\n",
    "            \n",
    "            # Save study results\n",
    "            study_path = Path(mlruns_dir) / experiment_name / \"optuna_studies\"\n",
    "            study_path.mkdir(parents=True, exist_ok=True)\n",
    "            joblib.dump(study, study_path / f\"study_{datetime.now().strftime('%Y%m%d_%H%M')}.pkl\")\n",
    "            \n",
    "            logger.info(f\"Training completed with precision: {final_metrics['precision']:.4f}\")\n",
    "            return final_metrics['precision']\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in hyperparameter optimization: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_precision_target(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    X_eval: np.ndarray,\n",
    "    y_eval: np.ndarray,\n",
    "    logger: ExperimentLogger) -> Tuple[Any, float, Dict[str, Any]]:\n",
    "    \"\"\"Train catboost model with target precision threshold.\"\"\"\n",
    "    \n",
    "    precision = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_params = None\n",
    "    best_seed = 0\n",
    "    best_model = None\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    # Base parameters from previous optimization\n",
    "    base_params = {\n",
    "        'learning_rate': 0.0460229201936893,\n",
    "        'max_depth': 11,\n",
    "        'min_child_weight': 72,\n",
    "        'subsample': 0.46392442652907506, \n",
    "        'colsample_bytree': 0.6671272425643389,\n",
    "        'reg_alpha': 0.7544589894634769,\n",
    "        'reg_lambda': 9.320178296187327,\n",
    "        'gamma': 0.782032150358923,\n",
    "        'early_stopping_rounds': 327,\n",
    "        'scale_pos_weight': 2.4844767951297175,\n",
    "        'tree_method': 'hist',  # Required for CPU-only training per project rules\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'AUC', \n",
    "        'verbose': 100,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    while best_precision < 0.48:  # Target precision threshold\n",
    "        for random_seed in range(1, 400):  # Try up to 1000 different seeds\n",
    "            logger.info(f\"Using sequential random seed: {random_seed}\")\n",
    "            \n",
    "            # Set all random seeds\n",
    "            os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "            np.random.seed(random_seed)\n",
    "            random.seed(random_seed)\n",
    "            base_params['random_state'] = random_seed\n",
    "            \n",
    "            try:\n",
    "                # Create and train model\n",
    "                model, metrics = train_model(\n",
    "                    X_train, y_train,\n",
    "                    X_test, y_test,\n",
    "                    X_eval, y_eval,\n",
    "                    **base_params\n",
    "                )\n",
    "                precision = metrics['precision']\n",
    "                recall = metrics['recall']\n",
    "\n",
    "                # Update best model if precision improved\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_recall = recall\n",
    "                    best_params = base_params.copy()\n",
    "                    best_seed = random_seed\n",
    "                    best_model = model\n",
    "                    logger.info(f\"New best precision: {precision:.4f} with seed {best_seed}\")\n",
    "                \n",
    "                # Check if target precision reached\n",
    "                if precision >= 0.48:\n",
    "                    logger.info(f\"Target precision achieved: {precision:.4f}\")\n",
    "                    return best_model, precision, recall, best_params\n",
    "                \n",
    "                logger.info(\n",
    "                    f\"Current precision: {precision:.4f}, \"\n",
    "                    f\"target: 0.4800, highest precision: {best_precision:.4f}, \"\n",
    "                    f\"best seed: {best_seed}\"\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error training with seed {random_seed}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Clear model to free memory\n",
    "            model = None\n",
    "        \n",
    "        # If target not reached after all seeds, return best model\n",
    "        if precision < 0.48:\n",
    "            logger.info(f\"Target precision not reached, using best seed: {best_seed}\")\n",
    "            return best_model, best_precision, best_recall, best_params\n",
    "            \n",
    "    return best_model, best_precision, best_recall, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_mlflow(model: object, precision: float, recall: float, params: dict, experiment_name: str) -> str:\n",
    "    \"\"\"Log model, metrics and parameters to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained catboost model\n",
    "        metrics (dict): Dictionary of metrics like precision, recall etc.\n",
    "        params (dict): Model parameters used for training\n",
    "        experiment_name (str): Name of the MLflow experiment\n",
    "    \"\"\"\n",
    "    from utils.create_evaluation_set import setup_mlflow_tracking\n",
    "    \n",
    "    mlruns_dir = setup_mlflow_tracking(experiment_name)\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"catboost_base_{datetime.now().strftime('%Y%m%d_%H%M')}\") as run:\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        })\n",
    "        \n",
    "        # Register model with timestamp\n",
    "        model_name = f\"catboost_base_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "        \n",
    "        # Log model with signature\n",
    "        input_example = pd.DataFrame(model.feature_names_in_[:1].copy())\n",
    "        signature = mlflow.models.infer_signature(\n",
    "            model_input=input_example,\n",
    "            model_output=predict_proba(model, input_example)\n",
    "        )\n",
    "        \n",
    "        mlflow.catboost.log_model(\n",
    "            xgb_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name,\n",
    "            signature=signature\n",
    "        )\n",
    "        \n",
    "        # Log run ID\n",
    "        run_id = run.info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "        return run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seed_model():\n",
    "    model, precision, recall, best_params = train_with_precision_target(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                logger\n",
    "            )\n",
    "    print(f\"Training completed with precision: {precision:.4f}\")\n",
    "    \n",
    "    # Log to MLflow if we got a valid model\n",
    "    if model is not None:\n",
    "        log_to_mlflow(model, precision, recall, best_params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 00:39:57,382] A new study created in memory with name: catboost_optimization_20250220_0039\n",
      "[W 2025-02-20 00:42:07,491] Trial 0 failed with parameters: {'learning_rate': 0.023688639503640783, 'depth': 12, 'min_data_in_leaf': 74, 'subsample': 0.5993292420985183, 'colsample_bylevel': 0.40921304830970556, 'reg_lambda': 1.525681189806849, 'leaf_estimation_iterations': 1, 'bagging_temperature': 4.330880728874676, 'scale_pos_weight': 9.415610164404923, 'early_stopping_rounds': 86} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\szita\\AppData\\Local\\Temp\\ipykernel_8052\\1933250848.py\", line 32, in objective\n",
      "    model, metrics = train_model(\n",
      "  File \"C:\\Users\\szita\\AppData\\Local\\Temp\\ipykernel_8052\\477178428.py\", line 12, in train_model\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\catboost\\core.py\", line 5245, in fit\n",
      "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n",
      "    self._train(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-20 00:42:07,493] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mhypertune_catboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[95], line 31\u001b[0m, in \u001b[0;36mhypertune_catboost\u001b[1;34m(experiment_name)\u001b[0m\n\u001b[0;32m     24\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tags({\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatboost_base\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     28\u001b[0m })\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7200\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 2 hours timeout\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Log best trial info\u001b[39;00m\n\u001b[0;32m     34\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[94], line 32\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     25\u001b[0m         params[param_name] \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\n\u001b[0;32m     26\u001b[0m             param_name,\n\u001b[0;32m     27\u001b[0m             param_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     28\u001b[0m             param_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     29\u001b[0m         )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Train model and get metrics\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m model, metrics \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[0;32m     33\u001b[0m     X_train, y_train,\n\u001b[0;32m     34\u001b[0m     X_test, y_test,\n\u001b[0;32m     35\u001b[0m     X_eval, y_eval,\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     39\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     40\u001b[0m precision \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[92], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_test, y_test, X_eval, y_eval, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m eval_set \u001b[38;5;241m=\u001b[39m Pool(X_test, y_test)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Fit model with early stopping\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get validation predictions\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_eval)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\catboost\\core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5246\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5247\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    hypertune_catboost(experiment_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccerpredictor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
