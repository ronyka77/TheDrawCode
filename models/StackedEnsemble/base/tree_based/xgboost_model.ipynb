{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model Implementation with CPU Optimization\n",
    "\n",
    "This notebook implements an XGBoost-based model for soccer match draw prediction with CPU optimization. The implementation includes:\n",
    "\n",
    "- Model creation and configuration\n",
    "- Training with early stopping\n",
    "- Threshold optimization\n",
    "- Hyperparameter tuning\n",
    "- Model evaluation\n",
    "- MLflow integration for experiment tracking\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:34:39,783 | INFO     | xgboost_soccer_prediction | Setting up MLflow tracking for experiment: xgboost_soccer_prediction\n",
      "mlflow local_path_uri: c:/Users/szita/Documents/TheDrawCode/mlruns\n",
      "2025-02-20 21:34:39,904 | INFO     | xgboost_soccer_prediction | Using existing experiment: xgboost_soccer_prediction experiment_id: 600562561289637747\n",
      "2025-02-20 21:34:39,904 | INFO     | xgboost_soccer_prediction | MLflow tracking configured successfully at: c:/Users/szita/Documents/TheDrawCode/mlruns\n",
      "2025-02-20 21:34:39,904 | INFO     | xgboost_soccer_prediction | Loading data splits according to ensemble strategy\n",
      "2025-02-20 21:34:39,904 | INFO     | xgboost_soccer_prediction | Returning features common to all models\n",
      "2025-02-20 21:34:39,915 | INFO     | xgboost_soccer_prediction | Loaded 102 selected features\n",
      "2025-02-20 21:34:39,980 | INFO     | xgboost_soccer_prediction | Loaded training data from parquet: c:\\Users\\szita\\Documents\\TheDrawCode\\data\\api_training_final.parquet\n",
      "2025-02-20 21:34:40,059 | INFO     | xgboost_soccer_prediction | Loaded training/test data:\n",
      " - Training samples: 22343\n",
      " - Test samples: 5586\n",
      "2025-02-20 21:34:40,060 | INFO     | xgboost_soccer_prediction | Loading training data from: c:\\Users\\szita\\Documents\\TheDrawCode\\data\\prediction\\api_prediction_eval.xlsx\n",
      "2025-02-20 21:34:50,308 | INFO     | xgboost_soccer_prediction | Ensemble evaluation set created with shape: (3399, 200)\n",
      "2025-02-20 21:34:50,313 | INFO     | xgboost_soccer_prediction | Draw rate: 26.60%\n",
      "2025-02-20 21:34:50,314 | INFO     | xgboost_soccer_prediction | Train set shape: (3399, 199)\n",
      "2025-02-20 21:34:50,314 | INFO     | xgboost_soccer_prediction | Test set shape: (3399,)\n",
      "2025-02-20 21:34:50,314 | INFO     | xgboost_soccer_prediction | Loaded validation data: 3399 samples\n",
      "2025-02-20 21:34:50,333 | INFO     | xgboost_soccer_prediction | Final data split sizes:\n",
      " - Train: (22343, 102) (for model training and nested CV)\n",
      " - Test: (5586, 102) (for early stopping during training)\n",
      " - Validation: (3399, 102) (held-out for evaluation and meta-features)\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Imports and Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import random\n",
    "from typing import Any, Dict, Tuple\n",
    "from datetime import datetime\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import yaml\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().absolute().parent.parent.parent.parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "os.environ[\"PYTHONPATH\"] = project_root + os.pathsep + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "os.environ[\"ARROW_S3_DISABLE\"] = \"1\"\n",
    "\n",
    "from utils.logger import ExperimentLogger\n",
    "experiment_name = \"xgboost_soccer_prediction\"\n",
    "logger = ExperimentLogger(experiment_name)\n",
    "\n",
    "from utils.create_evaluation_set import setup_mlflow_tracking\n",
    "from models.StackedEnsemble.utils.metrics import calculate_metrics\n",
    "from models.StackedEnsemble.shared.data_loader import DataLoader\n",
    "\n",
    "# Load data\n",
    "mlruns_dir = setup_mlflow_tracking(experiment_name)\n",
    "dataloader = DataLoader()\n",
    "X_train, y_train, X_test, y_test, X_eval, y_eval = dataloader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Configuration Loading\n",
    "def load_hyperparameter_space():\n",
    "    \"\"\"Define hyperparameter space for optimization.\"\"\"\n",
    "    try:\n",
    "        hyperparameter_space = {\n",
    "            'learning_rate': {\n",
    "                'type': 'float',\n",
    "                'low': 0.02,\n",
    "                'high': 0.06,\n",
    "                'log': True\n",
    "            },\n",
    "            'max_depth': {\n",
    "                'type': 'int', \n",
    "                'low': 8,\n",
    "                'high': 14\n",
    "            },\n",
    "            'min_child_weight': {\n",
    "                'type': 'int',\n",
    "                'low': 50,\n",
    "                'high': 100\n",
    "            },\n",
    "            'subsample': {\n",
    "                'type': 'float',\n",
    "                'low': 0.4,\n",
    "                'high': 0.7\n",
    "            },\n",
    "            'colsample_bytree': {\n",
    "                'type': 'float',\n",
    "                'low': 0.6,\n",
    "                'high': 0.8\n",
    "            },\n",
    "            'reg_alpha': {\n",
    "                'type': 'float',\n",
    "                'low': 0.01,\n",
    "                'high': 1.0,\n",
    "                'log': True\n",
    "            },\n",
    "            'reg_lambda': {\n",
    "                'type': 'float',\n",
    "                'low': 7.0,\n",
    "                'high': 12.0,\n",
    "                'log': True\n",
    "            },\n",
    "            'gamma': {\n",
    "                'type': 'float',\n",
    "                'low': 0.1,\n",
    "                'high': 1.0\n",
    "            },\n",
    "            'early_stopping_rounds': {\n",
    "                'type': 'int',\n",
    "                'low': 300,\n",
    "                'high': 350\n",
    "            },\n",
    "            'scale_pos_weight': {\n",
    "                'type': 'float',\n",
    "                'low': 2.4,\n",
    "                'high': 2.6\n",
    "            },\n",
    "            'rate_drop': {\n",
    "                'type': 'float',\n",
    "                'low': 0.03,\n",
    "                'high': 0.3\n",
    "            },\n",
    "            'skip_drop': {\n",
    "                'type': 'float',\n",
    "                'low': 0.2,\n",
    "                'high': 0.8\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # hyperparameter_space = {\n",
    "        #     'learning_rate': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 0.04,       # Focus around ~0.046\n",
    "        #         'high': 0.05,\n",
    "        #         'log': True\n",
    "        #     },\n",
    "        #     'max_depth': {\n",
    "        #         'type': 'int',\n",
    "        #         'low': 10,         # Narrow around best value 11\n",
    "        #         'high': 12\n",
    "        #     },\n",
    "        #     'min_child_weight': {\n",
    "        #         'type': 'int',\n",
    "        #         'low': 70,         # Focus near best 72\n",
    "        #         'high': 75\n",
    "        #     },\n",
    "        #     'subsample': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 0.45,       # Focus around 0.4639\n",
    "        #         'high': 0.48\n",
    "        #     },\n",
    "        #     'colsample_bytree': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 0.65,       # Focus near best 0.6671\n",
    "        #         'high': 0.70\n",
    "        #     },\n",
    "        #     'reg_alpha': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 0.7,        # Around best 0.7545\n",
    "        #         'high': 0.8,\n",
    "        #         'log': True\n",
    "        #     },\n",
    "        #     'reg_lambda': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 9.0,        # Nearly best 9.32\n",
    "        #         'high': 10.0,\n",
    "        #         'log': True\n",
    "        #     },\n",
    "        #     'gamma': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 0.75,       # Around best 0.7820\n",
    "        #         'high': 0.85\n",
    "        #     },\n",
    "        #     'early_stopping_rounds': {\n",
    "        #         'type': 'int',\n",
    "        #         'low': 300,        # Focused around best 327\n",
    "        #         'high': 350\n",
    "        #     },\n",
    "        #     'scale_pos_weight': {\n",
    "        #         'type': 'float',\n",
    "        #         'low': 2.4,        # Around best 2.4845\n",
    "        #         'high': 2.6\n",
    "        #     }\n",
    "        # }\n",
    "        \n",
    "        return hyperparameter_space\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating hyperparameter space: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "hyperparameter_space = load_hyperparameter_space()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Model Creation\n",
    "def create_model(**kwargs):\n",
    "    \"\"\"Create and configure XGBoost model instance.\"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': ['logloss', 'auc'],\n",
    "            'tree_method': 'hist',\n",
    "            'n_jobs': -1,\n",
    "            'verbosity': 0\n",
    "        }\n",
    "        \n",
    "        # Update with provided parameters\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        # Create model\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating XGBoost model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4: Data Conversion\n",
    "def convert_to_model_format(X: pd.DataFrame, y: pd.Series = None):\n",
    "    \"\"\"Convert data to XGBoost DMatrix format.\"\"\"\n",
    "    if X is None:\n",
    "        raise ValueError(\"The feature dataset X must not be None.\")\n",
    "    \n",
    "    try:\n",
    "        if y is not None:\n",
    "            dmatrix = xgb.DMatrix(X, label=y)\n",
    "        else:\n",
    "            dmatrix = xgb.DMatrix(X)\n",
    "        return dmatrix\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error converting data to DMatrix: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: Prediction Functions\n",
    "def predict(model, X, threshold=0.5):\n",
    "    \"\"\"Generate predictions using trained model.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before prediction\")\n",
    "        \n",
    "    try:\n",
    "        probas = model.predict_proba(X)[:, 1]\n",
    "        return (probas >= threshold).astype(int)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model prediction: {str(e)}\")\n",
    "        return np.zeros(len(X))\n",
    "\n",
    "def predict_proba(model, X):\n",
    "    \"\"\"Generate probability predictions.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before prediction\")\n",
    "        \n",
    "    try:\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in probability prediction: {str(e)}\")\n",
    "        return np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X: Any, y: Any, best_threshold: float) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on given data.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before evaluation\")\n",
    "    \n",
    "    try:\n",
    "        # Get probability predictions\n",
    "        y_prob = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Get binary predictions using best threshold\n",
    "        y_pred = (y_prob >= best_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = np.sum((y == 1) & (y_pred == 1))\n",
    "        fp = np.sum((y == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y == 1) & (y_pred == 0))\n",
    "        \n",
    "        metrics = {\n",
    "            'precision': tp / (tp + fp + 1e-10),\n",
    "            'recall': tp / (tp + fn + 1e-10),\n",
    "            'f1': 2 * tp / (2 * tp + fp + fn + 1e-10),\n",
    "            'auc': roc_auc_score(y, y_prob),\n",
    "            'brier_score': np.mean((y_prob - y) ** 2),\n",
    "            'threshold': best_threshold\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model evaluation: {str(e)}\")\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'auc': 0.0,\n",
    "            'brier_score': 1.0,\n",
    "            'threshold': best_threshold\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(model, y_true: np.ndarray, y_prob: np.ndarray) -> float:\n",
    "    \"\"\"Optimize prediction threshold with focus on precision while maintaining recall above 15%.\"\"\"\n",
    "    try:\n",
    "        best_threshold = 0.5\n",
    "        best_precision = 0.0\n",
    "        \n",
    "        # Search through thresholds\n",
    "        for threshold in np.linspace(0.3, 0.8, 51):\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            \n",
    "            # Calculate confusion matrix components\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            \n",
    "            precision = tp / (tp + fp + 1e-10)\n",
    "            recall = tp / (tp + fn + 1e-10)\n",
    "            \n",
    "            # Only consider thresholds that maintain recall above 15%\n",
    "            if recall >= 0.15:\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        logger.info(f\"Optimized threshold: {best_threshold:.3f} with precision: {best_precision:.3f}\")\n",
    "\n",
    "        metrics = evaluate(model, X_eval, y_eval, best_threshold)\n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error optimizing threshold: {str(e)}\")\n",
    "        return 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5: Training Function\n",
    "def train_model(X_train, y_train, X_test, y_test, X_eval, y_eval, **kwargs):\n",
    "    \"\"\"Train XGBoost model with early stopping.\"\"\"\n",
    "    try:\n",
    "        # Create model with remaining parameters\n",
    "        model = create_model(**kwargs)\n",
    "        \n",
    "        # Create eval set for early stopping\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        \n",
    "        # Fit model with early stopping\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Get validation predictions\n",
    "        y_prob = model.predict_proba(X_eval)[:, 1]\n",
    "        metrics = optimize_threshold(model, y_eval, y_prob)\n",
    "        \n",
    "        return model, metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error training XGBoost model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7: Model Save/Load\n",
    "def save_model(model, path, threshold=None):\n",
    "    \"\"\"Save XGBoost model and threshold to specified path.\"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        # Save model\n",
    "        joblib.dump(model, path)\n",
    "        \n",
    "        # Save threshold\n",
    "        if threshold:\n",
    "            threshold_path = path.parent / \"threshold.json\"\n",
    "            with open(threshold_path, 'w') as f:\n",
    "                json.dump({\n",
    "                    'threshold': threshold,\n",
    "                    'model_type': 'xgboost',\n",
    "                    'params': model.get_params()\n",
    "                }, f, indent=2)\n",
    "                \n",
    "        logger.info(f\"Model saved to {path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"Load XGBoost model from specified path.\"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"No model file found at {path}\")\n",
    "        \n",
    "    try:\n",
    "        # Load model\n",
    "        model = joblib.load(path)\n",
    "        \n",
    "        # Load threshold\n",
    "        threshold_path = path.parent / \"threshold.json\"\n",
    "        if threshold_path.exists():\n",
    "            with open(threshold_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                threshold = data.get('threshold', 0.5)\n",
    "        else:\n",
    "            threshold = 0.5\n",
    "            \n",
    "        logger.info(f\"Model loaded from {path}\")\n",
    "        return model, threshold\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8: Hyperparameter Tuning\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for hyperparameter optimization.\"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            # 'tree_method': 'hist',  # CPU-only as per requirements\n",
    "            'eval_metric': ['logloss', 'auc'],\n",
    "            'verbose': -1,\n",
    "            'n_jobs': -1,\n",
    "            'booster': 'dart',\n",
    "            'normalize_type': 'tree',\n",
    "            'sample_type': 'uniform',\n",
    "            'random_state': 19\n",
    "        }\n",
    "        \n",
    "        # Add hyperparameters from config\n",
    "        hyperparameter_space = load_hyperparameter_space()\n",
    "        for param_name, param_config in hyperparameter_space.items():\n",
    "            if param_config['type'] == 'float':\n",
    "                params[param_name] = trial.suggest_float(\n",
    "                    param_name,\n",
    "                    param_config['low'], \n",
    "                    param_config['high'],\n",
    "                    log=param_config.get('log', False)  # Pass log if in param_config, default False\n",
    "                )\n",
    "            elif param_config['type'] == 'int':\n",
    "                params[param_name] = trial.suggest_int(\n",
    "                    param_name,\n",
    "                    param_config['low'],\n",
    "                    param_config['high']\n",
    "                )\n",
    "            elif param_config['type'] == 'categorical':\n",
    "                params[param_name] = trial.suggest_categorical(\n",
    "                    param_name,\n",
    "                    param_config['choices']\n",
    "                )\n",
    "        # Train model and get metrics\n",
    "        model, metrics = train_model(\n",
    "            X_train, y_train,\n",
    "            X_test, y_test,\n",
    "            X_eval, y_eval,\n",
    "            **params\n",
    "        )\n",
    "        \n",
    "        recall = metrics.get('recall', 0.0)\n",
    "        precision = metrics.get('precision', 0.0)\n",
    "        \n",
    "        # Report intermediate values for pruning\n",
    "        trial.report(precision, step=1)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "        # Optimize for precision while maintaining minimum recall\n",
    "        score = precision if recall >= 0.15 else 0.0\n",
    "        \n",
    "        logger.info(f\"Trial {trial.number}:\")\n",
    "        logger.info(f\"  Params: {params}\")\n",
    "        logger.info(f\"  Score: {score}\")\n",
    "        \n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            trial.set_user_attr(metric_name, metric_value)\n",
    "        return score\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in trial {trial.number}: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 9: Hypertuning Function\n",
    "def hypertune_xgboost(experiment_name: str) -> float:\n",
    "    \"\"\"Run hyperparameter optimization with MLflow tracking.\"\"\"\n",
    "    try:\n",
    "        # Create study\n",
    "        study = optuna.create_study(\n",
    "            study_name=f\"xgboost_optimization_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "            direction=\"maximize\",\n",
    "            sampler=TPESampler(seed=42),\n",
    "            pruner=MedianPruner(n_startup_trials=5, n_warmup_steps=5)\n",
    "        )\n",
    "        \n",
    "        # Start MLflow run\n",
    "        with mlflow.start_run(run_name=f\"xgboost_optimization_{datetime.now().strftime('%Y%m%d_%H%M')}\"):\n",
    "            # Log dataset info\n",
    "            mlflow.log_params({\n",
    "                \"train_samples\": len(X_train),\n",
    "                \"test_samples\": len(X_test),\n",
    "                \"eval_samples\": len(X_eval),\n",
    "                \"features\": X_train.shape[1]\n",
    "            })\n",
    "            \n",
    "            # Set tags\n",
    "            mlflow.set_tags({\n",
    "                \"model_type\": \"xgboost_base\",\n",
    "                \"optimization\": \"optuna\",\n",
    "                \"cpu_only\": True\n",
    "            })\n",
    "            \n",
    "            # Optimize\n",
    "            study.optimize(objective, n_trials=50, timeout=7200)  # 2 hours timeout\n",
    "            \n",
    "            # Log best trial info\n",
    "            logger.info(f\"Best trial value: {study.best_value}\")\n",
    "            logger.info(f\"Best parameters found: {study.best_params}\")\n",
    "            \n",
    "            # Train final model with best parameters\n",
    "            logger.info(\"Training final model with best parameters\")\n",
    "            final_model, final_metrics = train_model(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                **study.best_params\n",
    "            )\n",
    "            \n",
    "            # Log best parameters and metrics\n",
    "            mlflow.log_params(study.best_params)\n",
    "            mlflow.log_metrics(final_metrics)\n",
    "            \n",
    "            # Create and log model signature\n",
    "            input_example = pd.DataFrame(X_train[:1].copy())\n",
    "            signature = mlflow.models.infer_signature(\n",
    "                model_input=input_example,\n",
    "                model_output=final_model.predict_proba(input_example)\n",
    "            )\n",
    "            \n",
    "            # Log model\n",
    "            mlflow.xgboost.log_model(\n",
    "                xgb_model=final_model,\n",
    "                artifact_path=\"xgboost_base_model\",\n",
    "                registered_model_name=f\"xgboost_base_{datetime.now().strftime('%Y%m%d_%H%M')}\",\n",
    "                signature=signature,\n",
    "                input_example=input_example\n",
    "            )\n",
    "            \n",
    "            # Save study results\n",
    "            study_path = Path(mlruns_dir) / experiment_name / \"optuna_studies\"\n",
    "            study_path.mkdir(parents=True, exist_ok=True)\n",
    "            joblib.dump(study, study_path / f\"study_{datetime.now().strftime('%Y%m%d_%H%M')}.pkl\")\n",
    "            \n",
    "            logger.info(f\"Training completed with precision: {final_metrics['precision']:.4f}\")\n",
    "            return final_metrics['precision']\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in hyperparameter optimization: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_precision_target(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    X_eval: np.ndarray,\n",
    "    y_eval: np.ndarray,\n",
    "    logger: ExperimentLogger) -> Tuple[Any, float, Dict[str, Any]]:\n",
    "    \"\"\"Train XGBoost model with target precision threshold.\"\"\"\n",
    "    \n",
    "    precision = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_params = None\n",
    "    best_seed = 0\n",
    "    best_model = None\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    # Base parameters from previous optimization\n",
    "    base_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': ['logloss', 'auc'],\n",
    "        'booster': 'dart',\n",
    "        'normalize_type': 'tree',\n",
    "        'sample_type': 'uniform',\n",
    "        'learning_rate': 0.030180820828066838,\n",
    "        'max_depth': 14,\n",
    "        'min_child_weight': 87,\n",
    "        'subsample': 0.579597545259111,\n",
    "        'colsample_bytree': 0.6312037280884872,\n",
    "        'reg_alpha': 0.020511104188433976,\n",
    "        'reg_lambda': 7.2226145454655,\n",
    "        'gamma': 0.8795585311974417,\n",
    "        'early_stopping_rounds': 330,\n",
    "        'scale_pos_weight': 2.541614515559209,\n",
    "        'rate_drop': 0.03555781345986666,\n",
    "        'skip_drop': 0.7819459112971967,\n",
    "        'tree_method': 'hist',\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    while best_precision < 0.48:  # Target precision threshold\n",
    "        for random_seed in range(1, 50):  # Try up to 1000 different seeds\n",
    "            logger.info(f\"Using sequential random seed: {random_seed}\")\n",
    "            \n",
    "            # Set all random seeds\n",
    "            os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "            np.random.seed(random_seed)\n",
    "            random.seed(random_seed)\n",
    "            base_params['random_state'] = random_seed\n",
    "            \n",
    "            try:\n",
    "                # Create and train model\n",
    "                model, metrics = train_model(\n",
    "                    X_train, y_train,\n",
    "                    X_test, y_test,\n",
    "                    X_eval, y_eval,\n",
    "                    **base_params\n",
    "                )\n",
    "                precision = metrics['precision']\n",
    "                recall = metrics['recall']\n",
    "\n",
    "                # Update best model if precision improved\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_recall = recall\n",
    "                    best_params = base_params.copy()\n",
    "                    best_seed = random_seed\n",
    "                    best_model = model\n",
    "                    logger.info(f\"New best precision: {precision:.4f} with seed {best_seed}\")\n",
    "                \n",
    "                # Check if target precision reached\n",
    "                if precision >= 0.48:\n",
    "                    logger.info(f\"Target precision achieved: {precision:.4f}\")\n",
    "                    return best_model, precision, recall, best_params\n",
    "                \n",
    "                logger.info(\n",
    "                    f\"Current precision: {precision:.4f}, \"\n",
    "                    f\"target: 0.4800, highest precision: {best_precision:.4f}, \"\n",
    "                    f\"best seed: {best_seed}\"\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error training with seed {random_seed}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Clear model to free memory\n",
    "            model = None\n",
    "        \n",
    "        # If target not reached after all seeds, return best model\n",
    "        if precision < 0.48:\n",
    "            logger.info(f\"Target precision not reached, using best seed: {best_seed}\")\n",
    "            return best_model, best_precision, best_recall, best_params\n",
    "            \n",
    "    return best_model, best_precision, best_recall, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_mlflow(model: object, precision: float, recall: float, params: dict, experiment_name: str) -> str:\n",
    "    \"\"\"Log model, metrics and parameters to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained XGBoost model\n",
    "        metrics (dict): Dictionary of metrics like precision, recall etc.\n",
    "        params (dict): Model parameters used for training\n",
    "        experiment_name (str): Name of the MLflow experiment\n",
    "    \"\"\"\n",
    "    from utils.create_evaluation_set import setup_mlflow_tracking\n",
    "    \n",
    "    mlruns_dir = setup_mlflow_tracking(experiment_name)\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"xgboost_base_{datetime.now().strftime('%Y%m%d_%H%M')}\") as run:\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        })\n",
    "        \n",
    "        # Register model with timestamp\n",
    "        model_name = f\"xgboost_base_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "        \n",
    "        # Log model with signature\n",
    "        input_example = pd.DataFrame(model.feature_names_in_[:1].copy(), dtype=float)\n",
    "        signature = mlflow.models.infer_signature(\n",
    "            model_input=input_example,\n",
    "            model_output=predict_proba(model, input_example)\n",
    "        )\n",
    "        \n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb_model=model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name,\n",
    "            signature=signature\n",
    "        )\n",
    "        \n",
    "        # Log run ID\n",
    "        run_id = run.info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "        return run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seed_model():\n",
    "    model, precision, recall, best_params = train_with_precision_target(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                logger\n",
    "            )\n",
    "    print(f\"Training completed with precision: {precision:.4f}\")\n",
    "    \n",
    "    # Log to MLflow if we got a valid model\n",
    "    if model is not None:\n",
    "        log_to_mlflow(model, precision, recall, best_params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:34:50,803] A new study created in memory with name: xgboost_optimization_20250220_2134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:35:37,336 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.550 with precision: 0.389\n",
      "2025-02-20 21:35:37,439 | INFO     | xgboost_soccer_prediction | Trial 0:\n",
      "2025-02-20 21:35:37,441 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.030180820828066838, 'max_depth': 14, 'min_child_weight': 87, 'subsample': 0.579597545259111, 'colsample_bytree': 0.6312037280884872, 'reg_alpha': 0.020511104188433976, 'reg_lambda': 7.2226145454655, 'gamma': 0.8795585311974417, 'early_stopping_rounds': 330, 'scale_pos_weight': 2.541614515559209, 'rate_drop': 0.03555781345986666, 'skip_drop': 0.7819459112971967}\n",
      "2025-02-20 21:35:37,442 | INFO     | xgboost_soccer_prediction |   Score: 0.3887468030689543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:35:37,446] Trial 0 finished with value: 0.3887468030689543 and parameters: {'learning_rate': 0.030180820828066838, 'max_depth': 14, 'min_child_weight': 87, 'subsample': 0.579597545259111, 'colsample_bytree': 0.6312037280884872, 'reg_alpha': 0.020511104188433976, 'reg_lambda': 7.2226145454655, 'gamma': 0.8795585311974417, 'early_stopping_rounds': 330, 'scale_pos_weight': 2.541614515559209, 'rate_drop': 0.03555781345986666, 'skip_drop': 0.7819459112971967}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:36:21,622 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.520 with precision: 0.360\n",
      "2025-02-20 21:36:21,682 | INFO     | xgboost_soccer_prediction | Trial 1:\n",
      "2025-02-20 21:36:21,685 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.049912126454217776, 'max_depth': 9, 'min_child_weight': 59, 'subsample': 0.45502135295603013, 'colsample_bytree': 0.6608484485919075, 'reg_alpha': 0.11207606211860566, 'reg_lambda': 8.83505209874092, 'gamma': 0.36210622617823773, 'early_stopping_rounds': 331, 'scale_pos_weight': 2.4278987721304084, 'rate_drop': 0.1088790551045089, 'skip_drop': 0.4198171059762151}\n",
      "2025-02-20 21:36:21,687 | INFO     | xgboost_soccer_prediction |   Score: 0.360381861575093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:36:21,689] Trial 1 finished with value: 0.360381861575093 and parameters: {'learning_rate': 0.049912126454217776, 'max_depth': 9, 'min_child_weight': 59, 'subsample': 0.45502135295603013, 'colsample_bytree': 0.6608484485919075, 'reg_alpha': 0.11207606211860566, 'reg_lambda': 8.83505209874092, 'gamma': 0.36210622617823773, 'early_stopping_rounds': 331, 'scale_pos_weight': 2.4278987721304084, 'rate_drop': 0.1088790551045089, 'skip_drop': 0.4198171059762151}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:37:07,351 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.530 with precision: 0.366\n",
      "2025-02-20 21:37:07,429 | INFO     | xgboost_soccer_prediction | Trial 2:\n",
      "2025-02-20 21:37:07,431 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.033008871633253174, 'max_depth': 13, 'min_child_weight': 60, 'subsample': 0.5542703315240834, 'colsample_bytree': 0.7184829137724085, 'reg_alpha': 0.012385137298860933, 'reg_lambda': 9.712121050648483, 'gamma': 0.2534717113185624, 'early_stopping_rounds': 303, 'scale_pos_weight': 2.589777107450667, 'rate_drop': 0.29072064893013105, 'skip_drop': 0.6850384088698768}\n",
      "2025-02-20 21:37:07,432 | INFO     | xgboost_soccer_prediction |   Score: 0.3660531697340765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:37:07,435] Trial 2 finished with value: 0.3660531697340765 and parameters: {'learning_rate': 0.033008871633253174, 'max_depth': 13, 'min_child_weight': 60, 'subsample': 0.5542703315240834, 'colsample_bytree': 0.7184829137724085, 'reg_alpha': 0.012385137298860933, 'reg_lambda': 9.712121050648483, 'gamma': 0.2534717113185624, 'early_stopping_rounds': 303, 'scale_pos_weight': 2.589777107450667, 'rate_drop': 0.29072064893013105, 'skip_drop': 0.6850384088698768}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:37:53,518 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.520 with precision: 0.356\n",
      "2025-02-20 21:37:53,612 | INFO     | xgboost_soccer_prediction | Trial 3:\n",
      "2025-02-20 21:37:53,614 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.02794909175335328, 'max_depth': 8, 'min_child_weight': 84, 'subsample': 0.5320457481218803, 'colsample_bytree': 0.6244076469689558, 'reg_alpha': 0.09780337016659407, 'reg_lambda': 7.1309569613760155, 'gamma': 0.9183883618709039, 'early_stopping_rounds': 313, 'scale_pos_weight': 2.5325044568707966, 'rate_drop': 0.11416199054414096, 'skip_drop': 0.5120408127066866}\n",
      "2025-02-20 21:37:53,616 | INFO     | xgboost_soccer_prediction |   Score: 0.3564356435642976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:37:53,618] Trial 3 finished with value: 0.3564356435642976 and parameters: {'learning_rate': 0.02794909175335328, 'max_depth': 8, 'min_child_weight': 84, 'subsample': 0.5320457481218803, 'colsample_bytree': 0.6244076469689558, 'reg_alpha': 0.09780337016659407, 'reg_lambda': 7.1309569613760155, 'gamma': 0.9183883618709039, 'early_stopping_rounds': 313, 'scale_pos_weight': 2.5325044568707966, 'rate_drop': 0.11416199054414096, 'skip_drop': 0.5120408127066866}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:38:39,764 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.520 with precision: 0.373\n",
      "2025-02-20 21:38:39,822 | INFO     | xgboost_soccer_prediction | Trial 4:\n",
      "2025-02-20 21:38:39,824 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.03646507323439208, 'max_depth': 9, 'min_child_weight': 99, 'subsample': 0.6325398470083343, 'colsample_bytree': 0.7878997883128378, 'reg_alpha': 0.6161049539380962, 'reg_lambda': 9.661763083808738, 'gamma': 0.9296868115208051, 'early_stopping_rounds': 304, 'scale_pos_weight': 2.439196572483829, 'rate_drop': 0.04221136800584528, 'skip_drop': 0.39519819845795867}\n",
      "2025-02-20 21:38:39,825 | INFO     | xgboost_soccer_prediction |   Score: 0.3734335839598062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:38:39,827] Trial 4 finished with value: 0.3734335839598062 and parameters: {'learning_rate': 0.03646507323439208, 'max_depth': 9, 'min_child_weight': 99, 'subsample': 0.6325398470083343, 'colsample_bytree': 0.7878997883128378, 'reg_alpha': 0.6161049539380962, 'reg_lambda': 9.661763083808738, 'gamma': 0.9296868115208051, 'early_stopping_rounds': 304, 'scale_pos_weight': 2.439196572483829, 'rate_drop': 0.04221136800584528, 'skip_drop': 0.39519819845795867}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:39:18,906 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.520 with precision: 0.344\n",
      "2025-02-20 21:39:19,008 | INFO     | xgboost_soccer_prediction | Trial 5:\n",
      "2025-02-20 21:39:19,010 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.03065322632598881, 'max_depth': 9, 'min_child_weight': 92, 'subsample': 0.5070259980080768, 'colsample_bytree': 0.6561869019374762, 'reg_alpha': 0.1217284708112243, 'reg_lambda': 7.552418274133421, 'gamma': 0.8219772826786357, 'early_stopping_rounds': 303, 'scale_pos_weight': 2.5973773873201034, 'rate_drop': 0.23850608771009751, 'skip_drop': 0.31922940892050344}\n",
      "2025-02-20 21:39:19,011 | INFO     | xgboost_soccer_prediction |   Score: 0.344230769230703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:39:19,014] Trial 5 finished with value: 0.344230769230703 and parameters: {'learning_rate': 0.03065322632598881, 'max_depth': 9, 'min_child_weight': 92, 'subsample': 0.5070259980080768, 'colsample_bytree': 0.6561869019374762, 'reg_alpha': 0.1217284708112243, 'reg_lambda': 7.552418274133421, 'gamma': 0.8219772826786357, 'early_stopping_rounds': 303, 'scale_pos_weight': 2.5973773873201034, 'rate_drop': 0.23850608771009751, 'skip_drop': 0.31922940892050344}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:40:01,913 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.510 with precision: 0.356\n",
      "2025-02-20 21:40:02,013 | INFO     | xgboost_soccer_prediction | Trial 6:\n",
      "2025-02-20 21:40:02,015 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.02012170210435754, 'max_depth': 13, 'min_child_weight': 86, 'subsample': 0.6187021504122961, 'colsample_bytree': 0.7542540693371892, 'reg_alpha': 0.014063366777718174, 'reg_lambda': 8.49197773852513, 'gamma': 0.20428215357261675, 'early_stopping_rounds': 344, 'scale_pos_weight': 2.5246596253655116, 'rate_drop': 0.11934246671021528, 'skip_drop': 0.2381350101716142}\n",
      "2025-02-20 21:40:02,016 | INFO     | xgboost_soccer_prediction |   Score: 0.35596330275222826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:40:02,018] Trial 6 finished with value: 0.35596330275222826 and parameters: {'learning_rate': 0.02012170210435754, 'max_depth': 13, 'min_child_weight': 86, 'subsample': 0.6187021504122961, 'colsample_bytree': 0.7542540693371892, 'reg_alpha': 0.014063366777718174, 'reg_lambda': 8.49197773852513, 'gamma': 0.20428215357261675, 'early_stopping_rounds': 344, 'scale_pos_weight': 2.5246596253655116, 'rate_drop': 0.11934246671021528, 'skip_drop': 0.2381350101716142}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:40:43,956 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.500 with precision: 0.354\n",
      "2025-02-20 21:40:44,011 | INFO     | xgboost_soccer_prediction | Trial 7:\n",
      "2025-02-20 21:40:44,012 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.028145325212664, 'max_depth': 10, 'min_child_weight': 87, 'subsample': 0.591267241406564, 'colsample_bytree': 0.7774425485152654, 'reg_alpha': 0.0879892974968902, 'reg_lambda': 7.466086969188792, 'gamma': 0.7419203085006955, 'early_stopping_rounds': 338, 'scale_pos_weight': 2.512255439513899, 'rate_drop': 0.23816113858773147, 'skip_drop': 0.4962773578186345}\n",
      "2025-02-20 21:40:44,015 | INFO     | xgboost_soccer_prediction |   Score: 0.353612167300313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:40:44,018] Trial 7 finished with value: 0.353612167300313 and parameters: {'learning_rate': 0.028145325212664, 'max_depth': 10, 'min_child_weight': 87, 'subsample': 0.591267241406564, 'colsample_bytree': 0.7774425485152654, 'reg_alpha': 0.0879892974968902, 'reg_lambda': 7.466086969188792, 'gamma': 0.7419203085006955, 'early_stopping_rounds': 338, 'scale_pos_weight': 2.512255439513899, 'rate_drop': 0.23816113858773147, 'skip_drop': 0.4962773578186345}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:41:27,867 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.510 with precision: 0.358\n",
      "2025-02-20 21:41:27,938 | INFO     | xgboost_soccer_prediction | Trial 8:\n",
      "2025-02-20 21:41:27,940 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.03551705428797813, 'max_depth': 10, 'min_child_weight': 51, 'subsample': 0.43236742809799134, 'colsample_bytree': 0.6062858371373469, 'reg_alpha': 0.18742210985555696, 'reg_lambda': 8.292462111660473, 'gamma': 0.5577136220482325, 'early_stopping_rounds': 346, 'scale_pos_weight': 2.4498584458297747, 'rate_drop': 0.14080338921962005, 'skip_drop': 0.6533306831258292}\n",
      "2025-02-20 21:41:27,941 | INFO     | xgboost_soccer_prediction |   Score: 0.3575757575756853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:41:27,942] Trial 8 finished with value: 0.3575757575756853 and parameters: {'learning_rate': 0.03551705428797813, 'max_depth': 10, 'min_child_weight': 51, 'subsample': 0.43236742809799134, 'colsample_bytree': 0.6062858371373469, 'reg_alpha': 0.18742210985555696, 'reg_lambda': 8.292462111660473, 'gamma': 0.5577136220482325, 'early_stopping_rounds': 346, 'scale_pos_weight': 2.4498584458297747, 'rate_drop': 0.14080338921962005, 'skip_drop': 0.6533306831258292}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:42:10,342 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.490 with precision: 0.352\n",
      "2025-02-20 21:42:10,393 | INFO     | xgboost_soccer_prediction | Trial 9:\n",
      "2025-02-20 21:42:10,394 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.025715469831766296, 'max_depth': 8, 'min_child_weight': 64, 'subsample': 0.44836638617620134, 'colsample_bytree': 0.7859395304685146, 'reg_alpha': 0.41327654594663626, 'reg_lambda': 9.84843498082888, 'gamma': 0.884314531168946, 'early_stopping_rounds': 340, 'scale_pos_weight': 2.437314011777207, 'rate_drop': 0.270990929592294, 'skip_drop': 0.5236053451493905}\n",
      "2025-02-20 21:42:10,396 | INFO     | xgboost_soccer_prediction |   Score: 0.35159817351590145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:42:10,398] Trial 9 finished with value: 0.35159817351590145 and parameters: {'learning_rate': 0.025715469831766296, 'max_depth': 8, 'min_child_weight': 64, 'subsample': 0.44836638617620134, 'colsample_bytree': 0.7859395304685146, 'reg_alpha': 0.41327654594663626, 'reg_lambda': 9.84843498082888, 'gamma': 0.884314531168946, 'early_stopping_rounds': 340, 'scale_pos_weight': 2.437314011777207, 'rate_drop': 0.270990929592294, 'skip_drop': 0.5236053451493905}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:42:57,107 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.540 with precision: 0.367\n",
      "2025-02-20 21:42:57,168 | INFO     | xgboost_soccer_prediction | Trial 10:\n",
      "2025-02-20 21:42:57,169 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.046974952362771674, 'max_depth': 14, 'min_child_weight': 75, 'subsample': 0.6796871025735362, 'colsample_bytree': 0.6795587300290153, 'reg_alpha': 0.03559158721596444, 'reg_lambda': 11.742599620345944, 'gamma': 0.6610388667665189, 'early_stopping_rounds': 321, 'scale_pos_weight': 2.5476811089450044, 'rate_drop': 0.03728769847573878, 'skip_drop': 0.767485831984228}\n",
      "2025-02-20 21:42:57,171 | INFO     | xgboost_soccer_prediction |   Score: 0.36699507389153524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:42:57,173] Trial 10 finished with value: 0.36699507389153524 and parameters: {'learning_rate': 0.046974952362771674, 'max_depth': 14, 'min_child_weight': 75, 'subsample': 0.6796871025735362, 'colsample_bytree': 0.6795587300290153, 'reg_alpha': 0.03559158721596444, 'reg_lambda': 11.742599620345944, 'gamma': 0.6610388667665189, 'early_stopping_rounds': 321, 'scale_pos_weight': 2.5476811089450044, 'rate_drop': 0.03728769847573878, 'skip_drop': 0.767485831984228}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:43:44,759 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.500 with precision: 0.354\n",
      "2025-02-20 21:43:44,809 | INFO     | xgboost_soccer_prediction | Trial 11:\n",
      "2025-02-20 21:43:44,811 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.04148683982235495, 'max_depth': 11, 'min_child_weight': 100, 'subsample': 0.6578618084185924, 'colsample_bytree': 0.7217904722722699, 'reg_alpha': 0.9912861232764341, 'reg_lambda': 10.90493451189929, 'gamma': 0.9689797840905632, 'early_stopping_rounds': 321, 'scale_pos_weight': 2.4691387490496535, 'rate_drop': 0.03930809838827523, 'skip_drop': 0.3646909839694887}\n",
      "2025-02-20 21:43:44,812 | INFO     | xgboost_soccer_prediction |   Score: 0.3539094650205033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:43:44,815] Trial 11 finished with value: 0.3539094650205033 and parameters: {'learning_rate': 0.04148683982235495, 'max_depth': 11, 'min_child_weight': 100, 'subsample': 0.6578618084185924, 'colsample_bytree': 0.7217904722722699, 'reg_alpha': 0.9912861232764341, 'reg_lambda': 10.90493451189929, 'gamma': 0.9689797840905632, 'early_stopping_rounds': 321, 'scale_pos_weight': 2.4691387490496535, 'rate_drop': 0.03930809838827523, 'skip_drop': 0.3646909839694887}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:44:29,179 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.500 with precision: 0.360\n",
      "2025-02-20 21:44:29,224 | INFO     | xgboost_soccer_prediction | Trial 12:\n",
      "2025-02-20 21:44:29,226 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.03821772297568998, 'max_depth': 12, 'min_child_weight': 100, 'subsample': 0.6167908328257539, 'colsample_bytree': 0.6375065262866735, 'reg_alpha': 0.04008750894196903, 'reg_lambda': 10.119579279798469, 'gamma': 0.6981188704051018, 'early_stopping_rounds': 330, 'scale_pos_weight': 2.478097151016992, 'rate_drop': 0.07201602451573741, 'skip_drop': 0.615337251759423}\n",
      "2025-02-20 21:44:29,227 | INFO     | xgboost_soccer_prediction |   Score: 0.35999999999991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:44:29,229] Trial 12 finished with value: 0.35999999999991 and parameters: {'learning_rate': 0.03821772297568998, 'max_depth': 12, 'min_child_weight': 100, 'subsample': 0.6167908328257539, 'colsample_bytree': 0.6375065262866735, 'reg_alpha': 0.04008750894196903, 'reg_lambda': 10.119579279798469, 'gamma': 0.6981188704051018, 'early_stopping_rounds': 330, 'scale_pos_weight': 2.478097151016992, 'rate_drop': 0.07201602451573741, 'skip_drop': 0.615337251759423}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:45:15,080 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.500 with precision: 0.352\n",
      "2025-02-20 21:45:15,149 | INFO     | xgboost_soccer_prediction | Trial 13:\n",
      "2025-02-20 21:45:15,151 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.02319133610896181, 'max_depth': 14, 'min_child_weight': 76, 'subsample': 0.698805096808364, 'colsample_bytree': 0.7499027381096706, 'reg_alpha': 0.7725265944884544, 'reg_lambda': 8.148773933900314, 'gamma': 0.993949337404659, 'early_stopping_rounds': 312, 'scale_pos_weight': 2.4056417529276093, 'rate_drop': 0.18648283335583749, 'skip_drop': 0.7815619112292309}\n",
      "2025-02-20 21:45:15,153 | INFO     | xgboost_soccer_prediction |   Score: 0.35159817351590145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:45:15,156] Trial 13 finished with value: 0.35159817351590145 and parameters: {'learning_rate': 0.02319133610896181, 'max_depth': 14, 'min_child_weight': 76, 'subsample': 0.698805096808364, 'colsample_bytree': 0.7499027381096706, 'reg_alpha': 0.7725265944884544, 'reg_lambda': 8.148773933900314, 'gamma': 0.993949337404659, 'early_stopping_rounds': 312, 'scale_pos_weight': 2.4056417529276093, 'rate_drop': 0.18648283335583749, 'skip_drop': 0.7815619112292309}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:45:59,643 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.520 with precision: 0.341\n",
      "2025-02-20 21:45:59,691 | INFO     | xgboost_soccer_prediction | Trial 14:\n",
      "2025-02-20 21:45:59,693 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.05602222486612514, 'max_depth': 11, 'min_child_weight': 93, 'subsample': 0.5772709685512647, 'colsample_bytree': 0.693618926090156, 'reg_alpha': 0.030098495059075782, 'reg_lambda': 9.245500608168445, 'gamma': 0.47531326143087926, 'early_stopping_rounds': 312, 'scale_pos_weight': 2.559807737669324, 'rate_drop': 0.07599957821357281, 'skip_drop': 0.2255208645736722}\n",
      "2025-02-20 21:45:59,695 | INFO     | xgboost_soccer_prediction |   Score: 0.34085213032572914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:45:59,698] Trial 14 finished with value: 0.34085213032572914 and parameters: {'learning_rate': 0.05602222486612514, 'max_depth': 11, 'min_child_weight': 93, 'subsample': 0.5772709685512647, 'colsample_bytree': 0.693618926090156, 'reg_alpha': 0.030098495059075782, 'reg_lambda': 9.245500608168445, 'gamma': 0.47531326143087926, 'early_stopping_rounds': 312, 'scale_pos_weight': 2.559807737669324, 'rate_drop': 0.07599957821357281, 'skip_drop': 0.2255208645736722}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:46:43,255 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.530 with precision: 0.378\n",
      "2025-02-20 21:46:43,358 | INFO     | xgboost_soccer_prediction | Trial 15:\n",
      "2025-02-20 21:46:43,361 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.041168779103102425, 'max_depth': 12, 'min_child_weight': 78, 'subsample': 0.6342573933173002, 'colsample_bytree': 0.6029790683414578, 'reg_alpha': 0.36214832725020857, 'reg_lambda': 10.73522873224571, 'gamma': 0.7898611821164133, 'early_stopping_rounds': 328, 'scale_pos_weight': 2.478546520380244, 'rate_drop': 0.1848961562265099, 'skip_drop': 0.422210128807625}\n",
      "2025-02-20 21:46:43,362 | INFO     | xgboost_soccer_prediction |   Score: 0.37783375314851947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:46:43,365] Trial 15 finished with value: 0.37783375314851947 and parameters: {'learning_rate': 0.041168779103102425, 'max_depth': 12, 'min_child_weight': 78, 'subsample': 0.6342573933173002, 'colsample_bytree': 0.6029790683414578, 'reg_alpha': 0.36214832725020857, 'reg_lambda': 10.73522873224571, 'gamma': 0.7898611821164133, 'early_stopping_rounds': 328, 'scale_pos_weight': 2.478546520380244, 'rate_drop': 0.1848961562265099, 'skip_drop': 0.422210128807625}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:47:27,007 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.500 with precision: 0.340\n",
      "2025-02-20 21:47:27,063 | INFO     | xgboost_soccer_prediction | Trial 16:\n",
      "2025-02-20 21:47:27,065 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.04198569367059674, 'max_depth': 13, 'min_child_weight': 77, 'subsample': 0.5021412125408873, 'colsample_bytree': 0.601258748446663, 'reg_alpha': 0.3106537636804185, 'reg_lambda': 10.883166304596243, 'gamma': 0.8225687973622664, 'early_stopping_rounds': 329, 'scale_pos_weight': 2.4921107228281536, 'rate_drop': 0.18915759280735395, 'skip_drop': 0.6040080227926612}\n",
      "2025-02-20 21:47:27,066 | INFO     | xgboost_soccer_prediction |   Score: 0.3398692810456961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:47:27,068] Trial 16 finished with value: 0.3398692810456961 and parameters: {'learning_rate': 0.04198569367059674, 'max_depth': 13, 'min_child_weight': 77, 'subsample': 0.5021412125408873, 'colsample_bytree': 0.601258748446663, 'reg_alpha': 0.3106537636804185, 'reg_lambda': 10.883166304596243, 'gamma': 0.8225687973622664, 'early_stopping_rounds': 329, 'scale_pos_weight': 2.4921107228281536, 'rate_drop': 0.18915759280735395, 'skip_drop': 0.6040080227926612}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:48:12,552 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.540 with precision: 0.372\n",
      "2025-02-20 21:48:12,650 | INFO     | xgboost_soccer_prediction | Trial 17:\n",
      "2025-02-20 21:48:12,652 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.05942776745504871, 'max_depth': 12, 'min_child_weight': 69, 'subsample': 0.5825768431059513, 'colsample_bytree': 0.6303193661239712, 'reg_alpha': 0.05850537424833965, 'reg_lambda': 11.71092545175463, 'gamma': 0.5660356488988221, 'early_stopping_rounds': 335, 'scale_pos_weight': 2.5576587534894433, 'rate_drop': 0.1696851926077981, 'skip_drop': 0.4564584234224811}\n",
      "2025-02-20 21:48:12,654 | INFO     | xgboost_soccer_prediction |   Score: 0.37162162162153795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:48:12,657] Trial 17 finished with value: 0.37162162162153795 and parameters: {'learning_rate': 0.05942776745504871, 'max_depth': 12, 'min_child_weight': 69, 'subsample': 0.5825768431059513, 'colsample_bytree': 0.6303193661239712, 'reg_alpha': 0.05850537424833965, 'reg_lambda': 11.71092545175463, 'gamma': 0.5660356488988221, 'early_stopping_rounds': 335, 'scale_pos_weight': 2.5576587534894433, 'rate_drop': 0.1696851926077981, 'skip_drop': 0.4564584234224811}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:48:56,947 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.510 with precision: 0.350\n",
      "2025-02-20 21:48:57,015 | INFO     | xgboost_soccer_prediction | Trial 18:\n",
      "2025-02-20 21:48:57,016 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.04602436290968198, 'max_depth': 12, 'min_child_weight': 82, 'subsample': 0.40019507329621057, 'colsample_bytree': 0.6562664367039676, 'reg_alpha': 0.0192253867948624, 'reg_lambda': 10.796373474008659, 'gamma': 0.770880285682364, 'early_stopping_rounds': 322, 'scale_pos_weight': 2.5009428552190403, 'rate_drop': 0.20596985864639786, 'skip_drop': 0.2992008835186403}\n",
      "2025-02-20 21:48:57,018 | INFO     | xgboost_soccer_prediction |   Score: 0.349907918968628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:48:57,020] Trial 18 finished with value: 0.349907918968628 and parameters: {'learning_rate': 0.04602436290968198, 'max_depth': 12, 'min_child_weight': 82, 'subsample': 0.40019507329621057, 'colsample_bytree': 0.6562664367039676, 'reg_alpha': 0.0192253867948624, 'reg_lambda': 10.796373474008659, 'gamma': 0.770880285682364, 'early_stopping_rounds': 322, 'scale_pos_weight': 2.5009428552190403, 'rate_drop': 0.20596985864639786, 'skip_drop': 0.2992008835186403}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:49:43,999 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.540 with precision: 0.386\n",
      "2025-02-20 21:49:44,115 | INFO     | xgboost_soccer_prediction | Trial 19:\n",
      "2025-02-20 21:49:44,116 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.03123273921472107, 'max_depth': 14, 'min_child_weight': 70, 'subsample': 0.6537723077572569, 'colsample_bytree': 0.6161684841194084, 'reg_alpha': 0.28755769908088563, 'reg_lambda': 7.969731393137238, 'gamma': 0.6591613633151673, 'early_stopping_rounds': 326, 'scale_pos_weight': 2.576072659847465, 'rate_drop': 0.14744229112097487, 'skip_drop': 0.7276123496307045}\n",
      "2025-02-20 21:49:44,118 | INFO     | xgboost_soccer_prediction |   Score: 0.38613861386129056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:49:44,120] Trial 19 finished with value: 0.38613861386129056 and parameters: {'learning_rate': 0.03123273921472107, 'max_depth': 14, 'min_child_weight': 70, 'subsample': 0.6537723077572569, 'colsample_bytree': 0.6161684841194084, 'reg_alpha': 0.28755769908088563, 'reg_lambda': 7.969731393137238, 'gamma': 0.6591613633151673, 'early_stopping_rounds': 326, 'scale_pos_weight': 2.576072659847465, 'rate_drop': 0.14744229112097487, 'skip_drop': 0.7276123496307045}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:50:30,452 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.510 with precision: 0.354\n",
      "2025-02-20 21:50:30,524 | INFO     | xgboost_soccer_prediction | Trial 20:\n",
      "2025-02-20 21:50:30,527 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.03176413878427415, 'max_depth': 14, 'min_child_weight': 70, 'subsample': 0.5457028940215505, 'colsample_bytree': 0.678899994530465, 'reg_alpha': 0.19559228099666226, 'reg_lambda': 7.809256156630913, 'gamma': 0.6249415843347221, 'early_stopping_rounds': 316, 'scale_pos_weight': 2.577529801934135, 'rate_drop': 0.08138857694235377, 'skip_drop': 0.7102199088839769}\n",
      "2025-02-20 21:50:30,529 | INFO     | xgboost_soccer_prediction |   Score: 0.35431918008779584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:50:30,532] Trial 20 finished with value: 0.35431918008779584 and parameters: {'learning_rate': 0.03176413878427415, 'max_depth': 14, 'min_child_weight': 70, 'subsample': 0.5457028940215505, 'colsample_bytree': 0.678899994530465, 'reg_alpha': 0.19559228099666226, 'reg_lambda': 7.809256156630913, 'gamma': 0.6249415843347221, 'early_stopping_rounds': 316, 'scale_pos_weight': 2.577529801934135, 'rate_drop': 0.08138857694235377, 'skip_drop': 0.7102199088839769}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:51:16,948 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.500 with precision: 0.365\n",
      "2025-02-20 21:51:16,997 | INFO     | xgboost_soccer_prediction | Trial 21:\n",
      "2025-02-20 21:51:16,999 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.02903489413278031, 'max_depth': 13, 'min_child_weight': 81, 'subsample': 0.6478895373632062, 'colsample_bytree': 0.6162487607802904, 'reg_alpha': 0.3756615413011831, 'reg_lambda': 7.365523684174454, 'gamma': 0.7906242212416662, 'early_stopping_rounds': 327, 'scale_pos_weight': 2.5342779918997067, 'rate_drop': 0.15173900988169994, 'skip_drop': 0.7310256004535236}\n",
      "2025-02-20 21:51:17,000 | INFO     | xgboost_soccer_prediction |   Score: 0.3645418326692501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:51:17,003] Trial 21 finished with value: 0.3645418326692501 and parameters: {'learning_rate': 0.02903489413278031, 'max_depth': 13, 'min_child_weight': 81, 'subsample': 0.6478895373632062, 'colsample_bytree': 0.6162487607802904, 'reg_alpha': 0.3756615413011831, 'reg_lambda': 7.365523684174454, 'gamma': 0.7906242212416662, 'early_stopping_rounds': 327, 'scale_pos_weight': 2.5342779918997067, 'rate_drop': 0.15173900988169994, 'skip_drop': 0.7310256004535236}. Best is trial 0 with value: 0.3887468030689543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 21:52:00,807 | INFO     | xgboost_soccer_prediction | Optimized threshold: 0.490 with precision: 0.329\n",
      "2025-02-20 21:52:00,850 | INFO     | xgboost_soccer_prediction | Trial 22:\n",
      "2025-02-20 21:52:00,852 | INFO     | xgboost_soccer_prediction |   Params: {'objective': 'binary:logistic', 'eval_metric': ['logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'booster': 'dart', 'normalize_type': 'tree', 'sample_type': 'uniform', 'random_state': 19, 'learning_rate': 0.02431725951489529, 'max_depth': 14, 'min_child_weight': 70, 'subsample': 0.6041698717741358, 'colsample_bytree': 0.6362967551069821, 'reg_alpha': 0.24686319407541057, 'reg_lambda': 7.056696953907927, 'gamma': 0.462438855590888, 'early_stopping_rounds': 334, 'scale_pos_weight': 2.575921309596674, 'rate_drop': 0.2145363618751568, 'skip_drop': 0.5776290911335666}\n",
      "2025-02-20 21:52:00,853 | INFO     | xgboost_soccer_prediction |   Score: 0.3291316526610183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 21:52:00,855] Trial 22 finished with value: 0.3291316526610183 and parameters: {'learning_rate': 0.02431725951489529, 'max_depth': 14, 'min_child_weight': 70, 'subsample': 0.6041698717741358, 'colsample_bytree': 0.6362967551069821, 'reg_alpha': 0.24686319407541057, 'reg_lambda': 7.056696953907927, 'gamma': 0.462438855590888, 'early_stopping_rounds': 334, 'scale_pos_weight': 2.575921309596674, 'rate_drop': 0.2145363618751568, 'skip_drop': 0.5776290911335666}. Best is trial 0 with value: 0.3887468030689543.\n",
      "[W 2025-02-20 21:52:11,198] Trial 23 failed with parameters: {'learning_rate': 0.03902088786039971, 'max_depth': 13, 'min_child_weight': 90, 'subsample': 0.6689778147765486, 'colsample_bytree': 0.6002847944241311, 'reg_alpha': 0.562336473344184, 'reg_lambda': 7.791242309411482, 'gamma': 0.8484086311810264, 'early_stopping_rounds': 325, 'scale_pos_weight': 2.466646339329373, 'rate_drop': 0.16405715958915698, 'skip_drop': 0.7854840624503119} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\szita\\AppData\\Local\\Temp\\ipykernel_23464\\2838245943.py\", line 39, in objective\n",
      "    model, metrics = train_model(\n",
      "  File \"C:\\Users\\szita\\AppData\\Local\\Temp\\ipykernel_23464\\2104137146.py\", line 12, in train_model\n",
      "    model.fit(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\sklearn.py\", line 1531, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-20 21:52:11,200] Trial 23 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# train_seed_model()\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mhypertune_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[189], line 31\u001b[0m, in \u001b[0;36mhypertune_xgboost\u001b[1;34m(experiment_name)\u001b[0m\n\u001b[0;32m     24\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tags({\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost_base\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptuna\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     28\u001b[0m })\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7200\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 2 hours timeout\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Log best trial info\u001b[39;00m\n\u001b[0;32m     34\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[188], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     34\u001b[0m         params[param_name] \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(\n\u001b[0;32m     35\u001b[0m             param_name,\n\u001b[0;32m     36\u001b[0m             param_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     37\u001b[0m         )\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Train model and get metrics\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m model, metrics \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[0;32m     40\u001b[0m     X_train, y_train,\n\u001b[0;32m     41\u001b[0m     X_test, y_test,\n\u001b[0;32m     42\u001b[0m     X_eval, y_eval,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     47\u001b[0m precision \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[186], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_test, y_test, X_eval, y_eval, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m eval_set \u001b[38;5;241m=\u001b[39m [(X_test, y_test)]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Fit model with early stopping\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Get validation predictions\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_eval)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_seed_model()\n",
    "    # hypertune_xgboost(experiment_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccerpredictor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
