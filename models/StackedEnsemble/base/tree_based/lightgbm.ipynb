{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 00:43:52,394 | INFO     | lightgbm_soccer_prediction | Setting up MLflow tracking for experiment: lightgbm_soccer_prediction\n",
      "mlflow local_path_uri: c:/Users/szita/Documents/TheDrawCode/mlruns\n",
      "2025-02-20 00:43:52,581 | INFO     | lightgbm_soccer_prediction | Using existing experiment: lightgbm_soccer_prediction experiment_id: 202086942006118315\n",
      "2025-02-20 00:43:52,581 | INFO     | lightgbm_soccer_prediction | MLflow tracking configured successfully at: c:/Users/szita/Documents/TheDrawCode/mlruns\n",
      "2025-02-20 00:43:52,581 | INFO     | lightgbm_soccer_prediction | Loading data splits according to ensemble strategy\n",
      "2025-02-20 00:43:52,581 | INFO     | lightgbm_soccer_prediction | Returning features common to all models\n",
      "2025-02-20 00:43:52,581 | INFO     | lightgbm_soccer_prediction | Loaded 102 selected features\n",
      "2025-02-20 00:43:52,648 | INFO     | lightgbm_soccer_prediction | Loaded training data from parquet: c:\\Users\\szita\\Documents\\TheDrawCode\\data\\api_training_final.parquet\n",
      "2025-02-20 00:43:52,715 | INFO     | lightgbm_soccer_prediction | Loaded training/test data:\n",
      " - Training samples: 22343\n",
      " - Test samples: 5586\n",
      "2025-02-20 00:43:52,718 | INFO     | lightgbm_soccer_prediction | Loading training data from: c:\\Users\\szita\\Documents\\TheDrawCode\\data\\prediction\\api_prediction_eval.xlsx\n",
      "2025-02-20 00:44:02,916 | INFO     | lightgbm_soccer_prediction | Ensemble evaluation set created with shape: (3395, 200)\n",
      "2025-02-20 00:44:02,916 | INFO     | lightgbm_soccer_prediction | Draw rate: 26.54%\n",
      "2025-02-20 00:44:02,916 | INFO     | lightgbm_soccer_prediction | Train set shape: (3395, 199)\n",
      "2025-02-20 00:44:02,932 | INFO     | lightgbm_soccer_prediction | Test set shape: (3395,)\n",
      "2025-02-20 00:44:02,932 | INFO     | lightgbm_soccer_prediction | Loaded validation data: 3395 samples\n",
      "2025-02-20 00:44:02,952 | INFO     | lightgbm_soccer_prediction | Final data split sizes:\n",
      " - Train: (22343, 102) (for model training and nested CV)\n",
      " - Test: (5586, 102) (for early stopping during training)\n",
      " - Validation: (3395, 102) (held-out for evaluation and meta-features)\n"
     ]
    }
   ],
   "source": [
    "# Block 1: Imports and Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.lightgbm\n",
    "import random\n",
    "from typing import Any, Dict, Tuple\n",
    "from datetime import datetime\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import yaml\n",
    "# Add project root to Python path\n",
    "project_root = str(Path().absolute().parent.parent.parent.parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "os.environ[\"PYTHONPATH\"] = project_root + os.pathsep + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "os.environ[\"ARROW_S3_DISABLE\"] = \"1\"\n",
    "\n",
    "from utils.logger import ExperimentLogger\n",
    "# Initialize logger\n",
    "experiment_name = \"lightgbm_soccer_prediction\"\n",
    "logger = ExperimentLogger(experiment_name)\n",
    "\n",
    "from utils.create_evaluation_set import setup_mlflow_tracking\n",
    "from models.StackedEnsemble.utils.metrics import calculate_metrics\n",
    "from models.StackedEnsemble.shared.data_loader import DataLoader\n",
    "\n",
    "mlruns_dir = setup_mlflow_tracking(experiment_name)\n",
    "\n",
    "# Load data\n",
    "dataloader = DataLoader()\n",
    "X_train, y_train, X_test, y_test, X_eval, y_eval = dataloader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Configuration Loading\n",
    "def load_hyperparameter_space():\n",
    "    try:\n",
    "        # Define hyperparameter space directly\n",
    "        hyperparameter_space = {\n",
    "            'learning_rate': {\n",
    "                'type': 'float',\n",
    "                'low': 0.10,\n",
    "                'high': 0.12,\n",
    "                'log': True\n",
    "            },\n",
    "            'num_leaves': {\n",
    "                'type': 'int', \n",
    "                'low': 45,\n",
    "                'high': 60\n",
    "            },\n",
    "            'max_depth': {\n",
    "                'type': 'int',\n",
    "                'low': 4,\n",
    "                'high': 6\n",
    "            },\n",
    "            'min_child_samples': {\n",
    "                'type': 'int',\n",
    "                'low': 150,\n",
    "                'high': 180\n",
    "            },\n",
    "            'feature_fraction': {\n",
    "                'type': 'float',\n",
    "                'low': 0.70,\n",
    "                'high': 0.85\n",
    "            },\n",
    "            'bagging_fraction': {\n",
    "                'type': 'float', \n",
    "                'low': 0.50,\n",
    "                'high': 0.65\n",
    "            },\n",
    "            'bagging_freq': {\n",
    "                'type': 'int',\n",
    "                'low': 5,\n",
    "                'high': 7\n",
    "            },\n",
    "            'reg_alpha': {\n",
    "                'type': 'float',\n",
    "                'low': 9.5,\n",
    "                'high': 11.5,\n",
    "                'log': True\n",
    "            },\n",
    "            'reg_lambda': {\n",
    "                'type': 'float',\n",
    "                'low': 7.5,\n",
    "                'high': 8.5,\n",
    "                'log': True\n",
    "            },\n",
    "            'min_split_gain': {\n",
    "                'type': 'float',\n",
    "                'low': 0.125,\n",
    "                'high': 0.15,\n",
    "                'log': True\n",
    "            },\n",
    "            'early_stopping_rounds': {\n",
    "                'type': 'int',\n",
    "                'low': 100,\n",
    "                'high': 1000\n",
    "            }\n",
    "        }\n",
    "        return hyperparameter_space\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating hyperparameter space: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "hyperparameter_space = load_hyperparameter_space()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Model Creation\n",
    "def create_model(**kwargs):\n",
    "    \"\"\"Create and configure LightGBM model instance.\"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': ['binary_logloss', 'auc'],\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        # Update with provided parameters\n",
    "        params.update(kwargs)\n",
    "        \n",
    "        # Create model\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        \n",
    "        # logger.info(f\"Created LightGBM model with parameters: {params}\")\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating LightGBM model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4: Data Conversion\n",
    "def convert_to_model_format(X: pd.DataFrame, y: pd.Series = None):\n",
    "    \"\"\"Convert data to LightGBM format.\"\"\"\n",
    "    if X is None:\n",
    "        raise ValueError(\"The feature dataset X must not be None.\")\n",
    "    \n",
    "    # LightGBM can handle pandas DataFrames directly\n",
    "    # Just ensure y is numeric if provided\n",
    "    if y is not None and isinstance(y, pd.Series):\n",
    "        y = y.astype(int)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5: Training Function\n",
    "def train_model(X_train, y_train, X_test, y_test, X_eval, y_eval, **kwargs):\n",
    "    \"\"\"Train LightGBM model with early stopping.\"\"\"\n",
    "    try:\n",
    "        # Extract early stopping rounds if present\n",
    "        early_stopping_rounds = kwargs.pop('early_stopping_rounds', 100)\n",
    "        \n",
    "        # Create model with remaining parameters\n",
    "        model = create_model(**kwargs)\n",
    "        \n",
    "        # Create eval set for early stopping\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        \n",
    "        # Fit model with early stopping\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds)]\n",
    "        )\n",
    "        \n",
    "        # Get validation predictions\n",
    "        y_prob = model.predict_proba(X_eval)[:, 1]\n",
    "        metrics = optimize_threshold(model, y_eval, y_prob)\n",
    "        \n",
    "        return model, metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error training LightGBM model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(model, y_true: np.ndarray, y_prob: np.ndarray) -> float:\n",
    "    \"\"\"Optimize prediction threshold with focus on precision while maintaining recall above 15%.\"\"\"\n",
    "    try:\n",
    "        best_threshold = 0.5\n",
    "        best_precision = 0.0\n",
    "        \n",
    "        # Search through thresholds\n",
    "        for threshold in np.linspace(0.3, 0.8, 51):\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            \n",
    "            # Calculate confusion matrix components\n",
    "            tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "            fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "            fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "            \n",
    "            precision = tp / (tp + fp + 1e-10)\n",
    "            recall = tp / (tp + fn + 1e-10)\n",
    "            \n",
    "            # Only consider thresholds that maintain recall above 15%\n",
    "            if recall >= 0.15:\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        logger.info(f\"Optimized threshold: {best_threshold:.3f} with precision: {best_precision:.3f}\")\n",
    "\n",
    "        metrics = evaluate(model, X_eval, y_eval, best_threshold)\n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error optimizing threshold: {str(e)}\")\n",
    "        return 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X: Any, y: Any, best_threshold: float) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on given data.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before evaluation\")\n",
    "    \n",
    "    try:\n",
    "        # Get probability predictions\n",
    "        y_prob = model.predict_proba(X)[:, 1]\n",
    "        \n",
    "        # Get binary predictions using best threshold\n",
    "        y_pred = (y_prob >= best_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = np.sum((y == 1) & (y_pred == 1))\n",
    "        fp = np.sum((y == 0) & (y_pred == 1))\n",
    "        fn = np.sum((y == 1) & (y_pred == 0))\n",
    "        \n",
    "        metrics = {\n",
    "            'precision': tp / (tp + fp + 1e-10),\n",
    "            'recall': tp / (tp + fn + 1e-10),\n",
    "            'f1': 2 * tp / (2 * tp + fp + fn + 1e-10),\n",
    "            'auc': roc_auc_score(y, y_prob),\n",
    "            'brier_score': np.mean((y_prob - y) ** 2),\n",
    "            'threshold': best_threshold\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model evaluation: {str(e)}\")\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'auc': 0.0,\n",
    "            'brier_score': 1.0,\n",
    "            'threshold': best_threshold\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6: Prediction Functions\n",
    "def predict(model, X, threshold=0.5):\n",
    "    \"\"\"Generate predictions using trained model.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before prediction\")\n",
    "        \n",
    "    try:\n",
    "        probas = model.predict_proba(X)[:, 1]\n",
    "        return (probas >= threshold).astype(int)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in model prediction: {str(e)}\")\n",
    "        return np.zeros(len(X))\n",
    "\n",
    "def predict_proba(model, X):\n",
    "    \"\"\"Generate probability predictions.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model must be trained before prediction\")\n",
    "        \n",
    "    try:\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in probability prediction: {str(e)}\")\n",
    "        return np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7: Model Persistence\n",
    "def save_model(model, path, threshold=0.5):\n",
    "    \"\"\"Save LightGBM model to specified path.\"\"\"\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"No model to save\")\n",
    "        \n",
    "    try:\n",
    "        # Create directory if it doesn't exist\n",
    "        path = Path(path)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(model, path)\n",
    "        \n",
    "        # Save threshold\n",
    "        threshold_path = path.parent / \"threshold.json\"\n",
    "        with open(threshold_path, 'w') as f:\n",
    "            json.dump({\n",
    "                'threshold': threshold,\n",
    "                'model_type': 'lightgbm',\n",
    "                'params': model.get_params()\n",
    "            }, f, indent=2)\n",
    "            \n",
    "        logger.info(f\"Model saved to {path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_model(path):\n",
    "    \"\"\"Load LightGBM model from specified path.\"\"\"\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"No model file found at {path}\")\n",
    "        \n",
    "    try:\n",
    "        # Load model\n",
    "        model = joblib.load(path)\n",
    "        \n",
    "        # Load threshold\n",
    "        threshold_path = path.parent / \"threshold.json\"\n",
    "        if threshold_path.exists():\n",
    "            with open(threshold_path, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                threshold = data.get('threshold', 0.5)\n",
    "        else:\n",
    "            threshold = 0.5\n",
    "            \n",
    "        logger.info(f\"Model loaded from {path}\")\n",
    "        return model, threshold\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading model: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 8: Feature Importance\n",
    "def get_feature_importance(model):\n",
    "    \"\"\"Get feature importance scores.\"\"\"\n",
    "    try:\n",
    "        # Get feature importance scores\n",
    "        feature_importance = model.feature_importances_\n",
    "        feature_names = model.feature_name_\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance\n",
    "        })\n",
    "        importance_df = importance_df.sort_values(\n",
    "            'importance',\n",
    "            ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "        \n",
    "        return importance_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error getting feature importance: {str(e)}\")\n",
    "        return pd.DataFrame(columns=['feature', 'importance'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 9: Hyperparameter Optimization\n",
    "def optimize_hyperparameters(X_train, y_train, X_test, y_test, X_eval, y_eval, hyperparameter_space):\n",
    "    \"\"\"Run hyperparameter optimization with Optuna.\"\"\"\n",
    "    logger.info(\"Starting hyperparameter optimization\")\n",
    "    \n",
    "    if not hyperparameter_space:\n",
    "        hyperparameter_space = load_hyperparameter_space()\n",
    "    best_score = 0.0\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            params = {\n",
    "                'objective': 'binary',\n",
    "                'metric': ['binary_logloss', 'auc'],\n",
    "                'verbose': -1,\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 19,\n",
    "                'device': 'cpu'\n",
    "            }\n",
    "            \n",
    "            # Add hyperparameters from config\n",
    "            for param_name, param_config in hyperparameter_space.items():\n",
    "                if param_config['type'] == 'float':\n",
    "                    params[param_name] = trial.suggest_float(\n",
    "                        param_name,\n",
    "                        param_config['low'],\n",
    "                        param_config['high'],\n",
    "                        log=param_config.get('log', False)\n",
    "                    )\n",
    "                elif param_config['type'] == 'int':\n",
    "                    params[param_name] = trial.suggest_int(\n",
    "                        param_name,\n",
    "                        param_config['low'],\n",
    "                        param_config['high']\n",
    "                    )\n",
    "\n",
    "            # Train model and get metrics\n",
    "            model, metrics = train_model(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                **params\n",
    "            )\n",
    "            \n",
    "            recall = metrics.get('recall', 0.0)\n",
    "            precision = metrics.get('precision', 0.0)\n",
    "            \n",
    "            # Report intermediate values for pruning\n",
    "            trial.report(precision, step=1)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "            \n",
    "            # Optimize for precision while maintaining minimum recall\n",
    "            score = precision if recall >= 0.15 else 0.0\n",
    "            \n",
    "            logger.info(f\"Trial {trial.number}:\")\n",
    "            logger.info(f\"  Params: {params}\")\n",
    "            # logger.info(f\"  Metrics: {metrics}\")\n",
    "            logger.info(f\"  Score: {score}\")\n",
    "            \n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                trial.set_user_attr(metric_name, metric_value)\n",
    "            return score\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Trial failed: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    try:\n",
    "        study = optuna.create_study(\n",
    "            study_name='lightgbm_optimization',\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=42),\n",
    "            pruner=MedianPruner(\n",
    "                n_startup_trials=5,\n",
    "                n_warmup_steps=2,\n",
    "                interval_steps=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=400,\n",
    "            timeout=7200,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'objective': 'binary',\n",
    "            'metric': ['binary_logloss', 'auc'],\n",
    "            'verbose': -1,\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 19,\n",
    "            'device': 'cpu'\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Best trial value: {study.best_value}\")\n",
    "        logger.info(f\"Best parameters found: {best_params}\")\n",
    "        return best_params\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in hyperparameter optimization: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 11: Main Training Function\n",
    "def hypertune_lightgbm(experiment_name: str) -> float:\n",
    "    \"\"\"Main training function with MLflow tracking.\"\"\"\n",
    "    try:\n",
    "        \n",
    "        \n",
    "        # Start MLflow run\n",
    "        with mlflow.start_run(run_name=f\"lightgbm_base_{datetime.now().strftime('%Y%m%d_%H%M')}\"):\n",
    "            # Log dataset info\n",
    "            mlflow.log_params({\n",
    "                \"train_samples\": len(X_train),\n",
    "                \"test_samples\": len(X_test),\n",
    "                \"eval_samples\": len(X_eval),\n",
    "                \"features\": X_train.shape[1]\n",
    "            })\n",
    "            \n",
    "            # Set tags\n",
    "            mlflow.set_tags({\n",
    "                \"model_type\": \"lightgbm_base\",\n",
    "                \"training_mode\": \"global\",\n",
    "                \"cpu_only\": True\n",
    "            })\n",
    "            \n",
    "            # Load hyperparameter space\n",
    "            hyperparameter_space = load_hyperparameter_space()\n",
    "            \n",
    "            # Run hyperparameter optimization\n",
    "            logger.info(\"Starting hyperparameter optimization\")\n",
    "            best_params = optimize_hyperparameters(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                hyperparameter_space=hyperparameter_space\n",
    "            )\n",
    "            \n",
    "            # Train final model with best parameters\n",
    "            logger.info(\"Training final model with best parameters\")\n",
    "            model, metrics = train_model(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                **best_params\n",
    "            )\n",
    "            \n",
    "            # Log metrics\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                mlflow.log_metric(f\"final_{metric_name}\", metric_value)\n",
    "            \n",
    "            # Log best parameters\n",
    "            mlflow.log_params(best_params)\n",
    "            \n",
    "            precision = metrics.get('precision', 0.0)\n",
    "            logger.info(f\"Training completed with precision: {precision:.4f}\")\n",
    "            \n",
    "            return precision\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in training main: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_precision_target(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    X_eval: np.ndarray,\n",
    "    y_eval: np.ndarray,\n",
    "    logger: ExperimentLogger) -> Tuple[Any, float, Dict[str, Any]]:\n",
    "    \"\"\"Train LightGBM model with target precision threshold.\"\"\"\n",
    "    \n",
    "    precision = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_params = None\n",
    "    best_seed = 0\n",
    "    best_model = None\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    # Set basic parameters\n",
    "    base_params = {\n",
    "        'learning_rate': 0.11840141811694627,\n",
    "        'num_leaves': 48,\n",
    "        'max_depth': 5,\n",
    "        'min_child_samples': 162,\n",
    "        'feature_fraction': 0.7101356750997326,\n",
    "        'bagging_fraction': 0.5457970189245859,\n",
    "        'bagging_freq': 7,\n",
    "        'reg_alpha': 10.679538431512006,\n",
    "        'reg_lambda': 8.051393466228827,\n",
    "        'min_split_gain': 0.1268039828994553,\n",
    "        'objective': 'binary',\n",
    "        'metric': ['binary_logloss', 'auc'],\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1,\n",
    "        'device': 'cpu',\n",
    "        'early_stopping_rounds': 550\n",
    "    }\n",
    "    \n",
    "    while best_precision < 0.48:  # Target precision threshold\n",
    "        for random_seed in range(1, 400):  # Try up to 300 different seeds\n",
    "            logger.info(f\"Using sequential random seed: {random_seed}\")\n",
    "            \n",
    "            # Set all random seeds\n",
    "            os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "            np.random.seed(random_seed)\n",
    "            random.seed(random_seed)\n",
    "            base_params['random_state'] = random_seed\n",
    "            \n",
    "            try:\n",
    "                # Create and train model\n",
    "                model, metrics = train_model(\n",
    "                    X_train, y_train,\n",
    "                    X_test, y_test,\n",
    "                    X_eval, y_eval,\n",
    "                    **base_params\n",
    "                )\n",
    "                precision = metrics['precision']\n",
    "                recall = metrics['recall']\n",
    "                \n",
    "                # Update best model if precision improved\n",
    "                if precision > best_precision:\n",
    "                    best_precision = precision\n",
    "                    best_params = base_params\n",
    "                    best_seed = random_seed\n",
    "                    best_recall = recall\n",
    "                    best_model = model\n",
    "                    logger.info(f\"New best precision: {precision:.4f} with seed {best_seed}\")\n",
    "                \n",
    "                # Check if target precision reached\n",
    "                if precision >= 0.48:\n",
    "                    logger.info(f\"Target precision achieved: {precision:.4f}\")\n",
    "                    return best_model, precision, recall, best_params\n",
    "                \n",
    "                logger.info(\n",
    "                    f\"Current precision: {precision:.4f}, \"\n",
    "                    f\"target: 0.4800, highest precision: {best_precision:.4f}, \"\n",
    "                    f\"best seed: {best_seed}\"\n",
    "                )\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error training with seed {random_seed}: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # Clear model to free memory\n",
    "            model = None\n",
    "        \n",
    "        # If target not reached after all seeds, return best model\n",
    "        if precision < 0.48:\n",
    "            logger.info(f\"Target precision not reached, using best seed: {best_seed}\")\n",
    "            return best_model, best_precision, best_recall, best_params\n",
    "    return best_model, best_precision, best_recall, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_mlflow(model: object, precision: float, recall: float, params: dict, experiment_name: str) -> str:\n",
    "    \"\"\"Log model, metrics and parameters to MLflow.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LightGBM model\n",
    "        metrics (dict): Dictionary of metrics like precision, recall etc.\n",
    "        params (dict): Model parameters used for training\n",
    "        experiment_name (str): Name of the MLflow experiment\n",
    "    \"\"\"\n",
    "    from utils.create_evaluation_set import setup_mlflow_tracking\n",
    "    \n",
    "    mlruns_dir = setup_mlflow_tracking(experiment_name)\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"lightgbm_base_{datetime.now().strftime('%Y%m%d_%H%M')}\") as run:\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall\n",
    "        })\n",
    "        \n",
    "        # Register model with timestamp\n",
    "        model_name = f\"lightgbm_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "        input_example = X_train.iloc[0]\n",
    "        # Log model with signature\n",
    "        signature = mlflow.models.infer_signature(\n",
    "            input_example,\n",
    "            predict(model, input_example)\n",
    "        )\n",
    "        \n",
    "        mlflow.lightgbm.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name,\n",
    "            signature=signature\n",
    "        )\n",
    "        \n",
    "        # Log run ID\n",
    "        run_id = run.info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "        return run_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seed_model():\n",
    "    model, precision, recall, best_params = train_with_precision_target(\n",
    "                X_train, y_train,\n",
    "                X_test, y_test,\n",
    "                X_eval, y_eval,\n",
    "                logger\n",
    "            )\n",
    "    print(f\"Training completed with precision: {precision:.4f}\")\n",
    "    \n",
    "    # Log to MLflow if we got a valid model\n",
    "    if model is not None:\n",
    "        log_to_mlflow(model, precision, recall, best_params, experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-20 00:44:03,457 | INFO     | lightgbm_soccer_prediction | Starting hyperparameter optimization\n",
      "2025-02-20 00:44:03,459 | INFO     | lightgbm_soccer_prediction | Starting hyperparameter optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-20 00:44:03,461] A new study created in memory with name: lightgbm_optimization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fcc7b52dbd40fa996a67746fd6552c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 118 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.564022\tvalid_0's auc: 0.599887\n",
      "2025-02-20 00:44:04,388 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.320 with precision: 0.333\n",
      "2025-02-20 00:44:04,405 | INFO     | lightgbm_soccer_prediction | Trial 0:\n",
      "2025-02-20 00:44:04,406 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.10706722664110592, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 168, 'feature_fraction': 0.7234027960663655, 'bagging_fraction': 0.5233991780504303, 'bagging_freq': 5, 'reg_alpha': 11.209697896046842, 'reg_lambda': 8.086050889160978, 'min_split_gain': 0.1422250457072074, 'early_stopping_rounds': 118}\n",
      "2025-02-20 00:44:04,408 | INFO     | lightgbm_soccer_prediction |   Score: 0.33277027027021405\n",
      "[I 2025-02-20 00:44:04,409] Trial 0 finished with value: 0.33277027027021405 and parameters: {'learning_rate': 0.10706722664110592, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 168, 'feature_fraction': 0.7234027960663655, 'bagging_fraction': 0.5233991780504303, 'bagging_freq': 5, 'reg_alpha': 11.209697896046842, 'reg_lambda': 8.086050889160978, 'min_split_gain': 0.1422250457072074, 'early_stopping_rounds': 118}. Best is trial 0 with value: 0.33277027027021405.\n",
      "Training until validation scores don't improve for 225 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.563638\tvalid_0's auc: 0.599568\n",
      "2025-02-20 00:44:05,127 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.330 with precision: 0.349\n",
      "2025-02-20 00:44:05,143 | INFO     | lightgbm_soccer_prediction | Trial 1:\n",
      "2025-02-20 00:44:05,145 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11934347261659847, 'num_leaves': 58, 'max_depth': 4, 'min_child_samples': 155, 'feature_fraction': 0.727510676478015, 'bagging_fraction': 0.5456363364439306, 'bagging_freq': 6, 'reg_alpha': 10.317249017144158, 'reg_lambda': 7.778427329735922, 'min_split_gain': 0.13975176052034569, 'early_stopping_rounds': 225}\n",
      "2025-02-20 00:44:05,147 | INFO     | lightgbm_soccer_prediction |   Score: 0.34920634920627003\n",
      "[I 2025-02-20 00:44:05,150] Trial 1 finished with value: 0.34920634920627003 and parameters: {'learning_rate': 0.11934347261659847, 'num_leaves': 58, 'max_depth': 4, 'min_child_samples': 155, 'feature_fraction': 0.727510676478015, 'bagging_fraction': 0.5456363364439306, 'bagging_freq': 6, 'reg_alpha': 10.317249017144158, 'reg_lambda': 7.778427329735922, 'min_split_gain': 0.13975176052034569, 'early_stopping_rounds': 225}. Best is trial 1 with value: 0.34920634920627003.\n",
      "Training until validation scores don't improve for 158 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.563839\tvalid_0's auc: 0.601974\n",
      "2025-02-20 00:44:05,923 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.340 with precision: 0.357\n",
      "2025-02-20 00:44:05,940 | INFO     | lightgbm_soccer_prediction | Trial 2:\n",
      "2025-02-20 00:44:05,941 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.10547083330378265, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 174, 'feature_fraction': 0.7299510673237539, 'bagging_fraction': 0.5771351657620417, 'bagging_freq': 6, 'reg_alpha': 9.58468386036785, 'reg_lambda': 8.092560992378745, 'min_split_gain': 0.12894732156565714, 'early_stopping_rounds': 158}\n",
      "2025-02-20 00:44:05,943 | INFO     | lightgbm_soccer_prediction |   Score: 0.3569682151588369\n",
      "[I 2025-02-20 00:44:05,945] Trial 2 finished with value: 0.3569682151588369 and parameters: {'learning_rate': 0.10547083330378265, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 174, 'feature_fraction': 0.7299510673237539, 'bagging_fraction': 0.5771351657620417, 'bagging_freq': 6, 'reg_alpha': 9.58468386036785, 'reg_lambda': 8.092560992378745, 'min_split_gain': 0.12894732156565714, 'early_stopping_rounds': 158}. Best is trial 2 with value: 0.3569682151588369.\n",
      "Training until validation scores don't improve for 919 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.564202\tvalid_0's auc: 0.596824\n",
      "2025-02-20 00:44:06,734 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.340 with precision: 0.383\n",
      "2025-02-20 00:44:06,751 | INFO     | lightgbm_soccer_prediction | Trial 3:\n",
      "2025-02-20 00:44:06,753 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11888688256542145, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 159, 'feature_fraction': 0.7146508171009576, 'bagging_fraction': 0.6026349539768235, 'bagging_freq': 6, 'reg_alpha': 9.724104883678166, 'reg_lambda': 7.9795412227855085, 'min_split_gain': 0.12578618310591014, 'early_stopping_rounds': 919}\n",
      "2025-02-20 00:44:06,755 | INFO     | lightgbm_soccer_prediction |   Score: 0.3825136612020813\n",
      "[I 2025-02-20 00:44:06,757] Trial 3 finished with value: 0.3825136612020813 and parameters: {'learning_rate': 0.11888688256542145, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 159, 'feature_fraction': 0.7146508171009576, 'bagging_fraction': 0.6026349539768235, 'bagging_freq': 6, 'reg_alpha': 9.724104883678166, 'reg_lambda': 7.9795412227855085, 'min_split_gain': 0.12578618310591014, 'early_stopping_rounds': 919}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 638 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.563885\tvalid_0's auc: 0.602019\n",
      "2025-02-20 00:44:07,419 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.340 with precision: 0.354\n",
      "2025-02-20 00:44:07,433 | INFO     | lightgbm_soccer_prediction | Trial 4:\n",
      "2025-02-20 00:44:07,435 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.10483119136156537, 'num_leaves': 55, 'max_depth': 4, 'min_child_samples': 166, 'feature_fraction': 0.7820065419014919, 'bagging_fraction': 0.5277281683288291, 'bagging_freq': 7, 'reg_alpha': 11.016399031752602, 'reg_lambda': 8.43587682056899, 'min_split_gain': 0.14715111513850343, 'early_stopping_rounds': 638}\n",
      "2025-02-20 00:44:07,437 | INFO     | lightgbm_soccer_prediction |   Score: 0.3541147132168693\n",
      "[I 2025-02-20 00:44:07,439] Trial 4 finished with value: 0.3541147132168693 and parameters: {'learning_rate': 0.10483119136156537, 'num_leaves': 55, 'max_depth': 4, 'min_child_samples': 166, 'feature_fraction': 0.7820065419014919, 'bagging_fraction': 0.5277281683288291, 'bagging_freq': 7, 'reg_alpha': 11.016399031752602, 'reg_lambda': 8.43587682056899, 'min_split_gain': 0.14715111513850343, 'early_stopping_rounds': 638}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 588 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[35]\tvalid_0's binary_logloss: 0.563296\tvalid_0's auc: 0.603098\n",
      "2025-02-20 00:44:08,129 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.330 with precision: 0.358\n",
      "2025-02-20 00:44:08,144 | INFO     | lightgbm_soccer_prediction | Trial 5:\n",
      "2025-02-20 00:44:08,146 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11830283458493492, 'num_leaves': 46, 'max_depth': 4, 'min_child_samples': 151, 'feature_fraction': 0.7487995496144896, 'bagging_fraction': 0.5583015934534223, 'bagging_freq': 5, 'reg_alpha': 11.12980271519947, 'reg_lambda': 7.842482174706608, 'min_split_gain': 0.13156935860937888, 'early_stopping_rounds': 588}\n",
      "2025-02-20 00:44:08,148 | INFO     | lightgbm_soccer_prediction |   Score: 0.3583959899748475\n",
      "[I 2025-02-20 00:44:08,151] Trial 5 finished with value: 0.3583959899748475 and parameters: {'learning_rate': 0.11830283458493492, 'num_leaves': 46, 'max_depth': 4, 'min_child_samples': 151, 'feature_fraction': 0.7487995496144896, 'bagging_fraction': 0.5583015934534223, 'bagging_freq': 5, 'reg_alpha': 11.12980271519947, 'reg_lambda': 7.842482174706608, 'min_split_gain': 0.13156935860937888, 'early_stopping_rounds': 588}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 794 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[41]\tvalid_0's binary_logloss: 0.562595\tvalid_0's auc: 0.60637\n",
      "2025-02-20 00:44:08,787 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.330 with precision: 0.347\n",
      "2025-02-20 00:44:08,803 | INFO     | lightgbm_soccer_prediction | Trial 6:\n",
      "2025-02-20 00:44:08,805 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.1026026447890488, 'num_leaves': 57, 'max_depth': 4, 'min_child_samples': 180, 'feature_fraction': 0.8158367153944985, 'bagging_fraction': 0.5298073522301259, 'bagging_freq': 5, 'reg_alpha': 11.101608135434493, 'reg_lambda': 8.19378145413348, 'min_split_gain': 0.1427689314122889, 'early_stopping_rounds': 794}\n",
      "2025-02-20 00:44:08,807 | INFO     | lightgbm_soccer_prediction |   Score: 0.347345132743286\n",
      "[I 2025-02-20 00:44:08,809] Trial 6 finished with value: 0.347345132743286 and parameters: {'learning_rate': 0.1026026447890488, 'num_leaves': 57, 'max_depth': 4, 'min_child_samples': 180, 'feature_fraction': 0.8158367153944985, 'bagging_fraction': 0.5298073522301259, 'bagging_freq': 5, 'reg_alpha': 11.101608135434493, 'reg_lambda': 8.19378145413348, 'min_split_gain': 0.1427689314122889, 'early_stopping_rounds': 794}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 674 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.563542\tvalid_0's auc: 0.60104\n",
      "2025-02-20 00:44:09,422 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.330 with precision: 0.353\n",
      "2025-02-20 00:44:09,438 | INFO     | lightgbm_soccer_prediction | Trial 7:\n",
      "2025-02-20 00:44:09,440 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.10135914717591736, 'num_leaves': 50, 'max_depth': 4, 'min_child_samples': 176, 'feature_fraction': 0.7934947190241337, 'bagging_fraction': 0.5496347037278974, 'bagging_freq': 5, 'reg_alpha': 10.081545756149998, 'reg_lambda': 7.811554526753263, 'min_split_gain': 0.14278452441422837, 'early_stopping_rounds': 674}\n",
      "2025-02-20 00:44:09,442 | INFO     | lightgbm_soccer_prediction |   Score: 0.3525179856114263\n",
      "[I 2025-02-20 00:44:09,444] Trial 7 finished with value: 0.3525179856114263 and parameters: {'learning_rate': 0.10135914717591736, 'num_leaves': 50, 'max_depth': 4, 'min_child_samples': 176, 'feature_fraction': 0.7934947190241337, 'bagging_fraction': 0.5496347037278974, 'bagging_freq': 5, 'reg_alpha': 10.081545756149998, 'reg_lambda': 7.811554526753263, 'min_split_gain': 0.14278452441422837, 'early_stopping_rounds': 674}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 122 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.563003\tvalid_0's auc: 0.603271\n",
      "2025-02-20 00:44:10,079 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.310 with precision: 0.356\n",
      "2025-02-20 00:44:10,093 | INFO     | lightgbm_soccer_prediction | Trial 8:\n",
      "2025-02-20 00:44:10,097 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11755757274861092, 'num_leaves': 52, 'max_depth': 4, 'min_child_samples': 172, 'feature_fraction': 0.8141177572925345, 'bagging_fraction': 0.5841915796354245, 'bagging_freq': 7, 'reg_alpha': 10.439889866178985, 'reg_lambda': 8.007110059393181, 'min_split_gain': 0.13513356792674885, 'early_stopping_rounds': 122}\n",
      "2025-02-20 00:44:10,098 | INFO     | lightgbm_soccer_prediction |   Score: 0.3562412342215489\n",
      "[I 2025-02-20 00:44:10,101] Trial 8 finished with value: 0.3562412342215489 and parameters: {'learning_rate': 0.11755757274861092, 'num_leaves': 52, 'max_depth': 4, 'min_child_samples': 172, 'feature_fraction': 0.8141177572925345, 'bagging_fraction': 0.5841915796354245, 'bagging_freq': 7, 'reg_alpha': 10.439889866178985, 'reg_lambda': 8.007110059393181, 'min_split_gain': 0.13513356792674885, 'early_stopping_rounds': 122}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 169 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.562931\tvalid_0's auc: 0.602796\n",
      "2025-02-20 00:44:10,857 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.330 with precision: 0.344\n",
      "2025-02-20 00:44:10,872 | INFO     | lightgbm_soccer_prediction | Trial 9:\n",
      "2025-02-20 00:44:10,873 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.10198656805954687, 'num_leaves': 45, 'max_depth': 5, 'min_child_samples': 159, 'feature_fraction': 0.7762856036747053, 'bagging_fraction': 0.6361349710889139, 'bagging_freq': 5, 'reg_alpha': 10.274834006128, 'reg_lambda': 8.243872323494392, 'min_split_gain': 0.13032464087329723, 'early_stopping_rounds': 169}\n",
      "2025-02-20 00:44:10,875 | INFO     | lightgbm_soccer_prediction |   Score: 0.34389140271485436\n",
      "[I 2025-02-20 00:44:10,877] Trial 9 finished with value: 0.34389140271485436 and parameters: {'learning_rate': 0.10198656805954687, 'num_leaves': 45, 'max_depth': 5, 'min_child_samples': 159, 'feature_fraction': 0.7762856036747053, 'bagging_fraction': 0.6361349710889139, 'bagging_freq': 5, 'reg_alpha': 10.274834006128, 'reg_lambda': 8.243872323494392, 'min_split_gain': 0.13032464087329723, 'early_stopping_rounds': 169}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 994 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[44]\tvalid_0's binary_logloss: 0.564497\tvalid_0's auc: 0.597179\n",
      "2025-02-20 00:44:11,727 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.300 with precision: 0.337\n",
      "2025-02-20 00:44:11,744 | INFO     | lightgbm_soccer_prediction | Trial 10:\n",
      "2025-02-20 00:44:11,746 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11273493996072519, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 160, 'feature_fraction': 0.7022010388010609, 'bagging_fraction': 0.6181763893480561, 'bagging_freq': 6, 'reg_alpha': 9.520279148312959, 'reg_lambda': 7.591581513742755, 'min_split_gain': 0.125280889072825, 'early_stopping_rounds': 994}\n",
      "2025-02-20 00:44:11,750 | INFO     | lightgbm_soccer_prediction |   Score: 0.3365617433413636\n",
      "[I 2025-02-20 00:44:11,752] Trial 10 finished with value: 0.3365617433413636 and parameters: {'learning_rate': 0.11273493996072519, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 160, 'feature_fraction': 0.7022010388010609, 'bagging_fraction': 0.6181763893480561, 'bagging_freq': 6, 'reg_alpha': 9.520279148312959, 'reg_lambda': 7.591581513742755, 'min_split_gain': 0.125280889072825, 'early_stopping_rounds': 994}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 411 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.564086\tvalid_0's auc: 0.599239\n",
      "2025-02-20 00:44:12,646 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.340 with precision: 0.362\n",
      "2025-02-20 00:44:12,664 | INFO     | lightgbm_soccer_prediction | Trial 11:\n",
      "2025-02-20 00:44:12,665 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11459867677595345, 'num_leaves': 46, 'max_depth': 6, 'min_child_samples': 150, 'feature_fraction': 0.7477429375187211, 'bagging_fraction': 0.6034835635024538, 'bagging_freq': 6, 'reg_alpha': 9.899937108729906, 'reg_lambda': 7.839239026039704, 'min_split_gain': 0.1324834145275993, 'early_stopping_rounds': 411}\n",
      "2025-02-20 00:44:12,666 | INFO     | lightgbm_soccer_prediction |   Score: 0.3622559652927631\n",
      "[I 2025-02-20 00:44:12,668] Trial 11 finished with value: 0.3622559652927631 and parameters: {'learning_rate': 0.11459867677595345, 'num_leaves': 46, 'max_depth': 6, 'min_child_samples': 150, 'feature_fraction': 0.7477429375187211, 'bagging_fraction': 0.6034835635024538, 'bagging_freq': 6, 'reg_alpha': 9.899937108729906, 'reg_lambda': 7.839239026039704, 'min_split_gain': 0.1324834145275993, 'early_stopping_rounds': 411}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 377 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[49]\tvalid_0's binary_logloss: 0.564124\tvalid_0's auc: 0.598177\n",
      "2025-02-20 00:44:13,498 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.350 with precision: 0.373\n",
      "2025-02-20 00:44:13,516 | INFO     | lightgbm_soccer_prediction | Trial 12:\n",
      "2025-02-20 00:44:13,518 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.11303529173498204, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 151, 'feature_fraction': 0.7522797916931567, 'bagging_fraction': 0.6067966703320118, 'bagging_freq': 6, 'reg_alpha': 9.857222080876936, 'reg_lambda': 7.619130434413218, 'min_split_gain': 0.12519510107280007, 'early_stopping_rounds': 377}\n",
      "2025-02-20 00:44:13,519 | INFO     | lightgbm_soccer_prediction |   Score: 0.37279596977320584\n",
      "[I 2025-02-20 00:44:13,521] Trial 12 finished with value: 0.37279596977320584 and parameters: {'learning_rate': 0.11303529173498204, 'num_leaves': 48, 'max_depth': 6, 'min_child_samples': 151, 'feature_fraction': 0.7522797916931567, 'bagging_fraction': 0.6067966703320118, 'bagging_freq': 6, 'reg_alpha': 9.857222080876936, 'reg_lambda': 7.619130434413218, 'min_split_gain': 0.12519510107280007, 'early_stopping_rounds': 377}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 424 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.563712\tvalid_0's auc: 0.598836\n",
      "2025-02-20 00:44:14,352 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.350 with precision: 0.377\n",
      "2025-02-20 00:44:14,369 | INFO     | lightgbm_soccer_prediction | Trial 13:\n",
      "2025-02-20 00:44:14,371 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.1114640896607551, 'num_leaves': 49, 'max_depth': 6, 'min_child_samples': 160, 'feature_fraction': 0.8448006919098183, 'bagging_fraction': 0.6476424912354288, 'bagging_freq': 7, 'reg_alpha': 9.814058724078278, 'reg_lambda': 7.534094433336659, 'min_split_gain': 0.12584613887456406, 'early_stopping_rounds': 424}\n",
      "2025-02-20 00:44:14,371 | INFO     | lightgbm_soccer_prediction |   Score: 0.3766578249335871\n",
      "[I 2025-02-20 00:44:14,373] Trial 13 finished with value: 0.3766578249335871 and parameters: {'learning_rate': 0.1114640896607551, 'num_leaves': 49, 'max_depth': 6, 'min_child_samples': 160, 'feature_fraction': 0.8448006919098183, 'bagging_fraction': 0.6476424912354288, 'bagging_freq': 7, 'reg_alpha': 9.814058724078278, 'reg_lambda': 7.534094433336659, 'min_split_gain': 0.12584613887456406, 'early_stopping_rounds': 424}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 982 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.563815\tvalid_0's auc: 0.598983\n",
      "2025-02-20 00:44:15,216 | INFO     | lightgbm_soccer_prediction | Optimized threshold: 0.330 with precision: 0.348\n",
      "2025-02-20 00:44:15,232 | INFO     | lightgbm_soccer_prediction | Trial 14:\n",
      "2025-02-20 00:44:15,234 | INFO     | lightgbm_soccer_prediction |   Params: {'objective': 'binary', 'metric': ['binary_logloss', 'auc'], 'verbose': -1, 'n_jobs': -1, 'random_state': 19, 'device': 'cpu', 'learning_rate': 0.10945412722983622, 'num_leaves': 53, 'max_depth': 5, 'min_child_samples': 161, 'feature_fraction': 0.8406341739049034, 'bagging_fraction': 0.6451035195623658, 'bagging_freq': 7, 'reg_alpha': 10.675428550941144, 'reg_lambda': 7.512225785401494, 'min_split_gain': 0.12791689225784517, 'early_stopping_rounds': 982}\n",
      "2025-02-20 00:44:15,235 | INFO     | lightgbm_soccer_prediction |   Score: 0.3478260869564461\n",
      "[I 2025-02-20 00:44:15,239] Trial 14 finished with value: 0.3478260869564461 and parameters: {'learning_rate': 0.10945412722983622, 'num_leaves': 53, 'max_depth': 5, 'min_child_samples': 161, 'feature_fraction': 0.8406341739049034, 'bagging_fraction': 0.6451035195623658, 'bagging_freq': 7, 'reg_alpha': 10.675428550941144, 'reg_lambda': 7.512225785401494, 'min_split_gain': 0.12791689225784517, 'early_stopping_rounds': 982}. Best is trial 3 with value: 0.3825136612020813.\n",
      "Training until validation scores don't improve for 420 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.563666\tvalid_0's auc: 0.601745\n",
      "[W 2025-02-20 00:44:16,269] Trial 15 failed with parameters: {'learning_rate': 0.11577187506045059, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 156, 'feature_fraction': 0.8420207389620346, 'bagging_fraction': 0.6250600744813755, 'bagging_freq': 7, 'reg_alpha': 9.816640720304866, 'reg_lambda': 8.42749505589772, 'min_split_gain': 0.13534722662957416, 'early_stopping_rounds': 420} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\szita\\AppData\\Local\\Temp\\ipykernel_19528\\3921615126.py\", line 37, in objective\n",
      "    model, metrics = train_model(\n",
      "  File \"C:\\Users\\szita\\AppData\\Local\\Temp\\ipykernel_19528\\4026404886.py\", line 22, in train_model\n",
      "    y_prob = model.predict_proba(X_eval)[:, 1]\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1351, in predict_proba\n",
      "    result = super().predict(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1036, in predict\n",
      "    return self._Booster.predict(  # type: ignore[union-attr]\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py\", line 4748, in predict\n",
      "    return predictor.predict(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py\", line 1139, in predict\n",
      "    data = _data_from_pandas(\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py\", line 848, in _data_from_pandas\n",
      "    _pandas_to_numpy(data, target_dtype=target_dtype),\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py\", line 797, in _pandas_to_numpy\n",
      "    return data.to_numpy(dtype=target_dtype, copy=False)\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\pandas\\core\\frame.py\", line 1889, in to_numpy\n",
      "    result = self._mgr.as_array(dtype=dtype, copy=copy, na_value=na_value)\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1656, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"c:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1715, in _interleave\n",
      "    result[rl.indexer] = arr\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-20 00:44:16,338] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[473], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m         precision \u001b[38;5;241m=\u001b[39m \u001b[43mhypertune_lightgbm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed with precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# train_seed_model()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[469], line 29\u001b[0m, in \u001b[0;36mhypertune_lightgbm\u001b[1;34m(experiment_name)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Run hyperparameter optimization\u001b[39;00m\n\u001b[0;32m     28\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting hyperparameter optimization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_space\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train final model with best parameters\u001b[39;00m\n\u001b[0;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining final model with best parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[468], line 80\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(X_train, y_train, X_test, y_test, X_eval, y_eval, hyperparameter_space)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m     70\u001b[0m         study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgbm_optimization\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     71\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     )\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[0;32m     88\u001b[0m     best_params\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m     })\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[468], line 37\u001b[0m, in \u001b[0;36moptimize_hyperparameters.<locals>.objective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     30\u001b[0m         params[param_name] \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_int(\n\u001b[0;32m     31\u001b[0m             param_name,\n\u001b[0;32m     32\u001b[0m             param_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     33\u001b[0m             param_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     34\u001b[0m         )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Train model and get metrics\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m model, metrics \u001b[38;5;241m=\u001b[39m train_model(\n\u001b[0;32m     38\u001b[0m     X_train, y_train,\n\u001b[0;32m     39\u001b[0m     X_test, y_test,\n\u001b[0;32m     40\u001b[0m     X_eval, y_eval,\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     44\u001b[0m recall \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     45\u001b[0m precision \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[462], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_test, y_test, X_eval, y_eval, **kwargs)\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     16\u001b[0m     X_train, y_train,\n\u001b[0;32m     17\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39meval_set,\n\u001b[0;32m     18\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds)]\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get validation predictions\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_eval\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     23\u001b[0m metrics \u001b[38;5;241m=\u001b[39m optimize_threshold(model, y_eval, y_prob)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, metrics\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\sklearn.py:1351\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_proba\u001b[39m(\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1341\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1349\u001b[0m ):\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m   1352\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   1353\u001b[0m         raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   1354\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1355\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1356\u001b[0m         pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   1357\u001b[0m         pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   1358\u001b[0m         validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1359\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1360\u001b[0m     )\n\u001b[0;32m   1361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_objective) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (raw_score \u001b[38;5;129;01mor\u001b[39;00m pred_leaf \u001b[38;5;129;01mor\u001b[39;00m pred_contrib):\n\u001b[0;32m   1362\u001b[0m         _log_warning(\n\u001b[0;32m   1363\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compute class probabilities or labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1364\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to the usage of customized objective function.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1365\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning raw scores instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\sklearn.py:1036\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   1033\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m _choose_param_value(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m, predict_params, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m   1034\u001b[0m predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_n_jobs(predict_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 1036\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mpredict(  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     X,\n\u001b[0;32m   1038\u001b[0m     raw_score\u001b[38;5;241m=\u001b[39mraw_score,\n\u001b[0;32m   1039\u001b[0m     start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1040\u001b[0m     num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1041\u001b[0m     pred_leaf\u001b[38;5;241m=\u001b[39mpred_leaf,\n\u001b[0;32m   1042\u001b[0m     pred_contrib\u001b[38;5;241m=\u001b[39mpred_contrib,\n\u001b[0;32m   1043\u001b[0m     validate_features\u001b[38;5;241m=\u001b[39mvalidate_features,\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params,\n\u001b[0;32m   1045\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py:4748\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4746\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4747\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py:1139\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     _safe_call(\n\u001b[0;32m   1131\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterValidateFeatureNames(\n\u001b[0;32m   1132\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1135\u001b[0m         )\n\u001b[0;32m   1136\u001b[0m     )\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd_DataFrame):\n\u001b[1;32m-> 1139\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1146\u001b[0m predict_type \u001b[38;5;241m=\u001b[39m _C_API_PREDICT_NORMAL\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_score:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py:848\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    844\u001b[0m df_dtypes\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    845\u001b[0m target_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdf_dtypes)\n\u001b[0;32m    847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 848\u001b[0m     \u001b[43m_pandas_to_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    849\u001b[0m     feature_name,\n\u001b[0;32m    850\u001b[0m     categorical_feature,\n\u001b[0;32m    851\u001b[0m     pandas_categorical,\n\u001b[0;32m    852\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\lightgbm\\basic.py:797\u001b[0m, in \u001b[0;36m_pandas_to_numpy\u001b[1;34m(data, target_dtype)\u001b[0m\n\u001b[0;32m    794\u001b[0m _check_for_bad_pandas_dtypes(data\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# most common case (no nullable dtypes)\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;66;03m# 1.0 <= pd version < 1.1 and nullable dtypes, least common case\u001b[39;00m\n\u001b[0;32m    800\u001b[0m     \u001b[38;5;66;03m# raises error because array is casted to type(pd.NA) and there's no na_value argument\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mastype(target_dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\pandas\\core\\frame.py:1889\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1888\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1889\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1891\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\szita\\.conda\\envs\\soccerpredictor_env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1715\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1713\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1715\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1716\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Block 12: Run Training\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # precision = hypertune_lightgbm(experiment_name)\n",
    "        # print(f\"Training completed with precision: {precision:.4f}\")\n",
    "        \n",
    "        train_seed_model()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Training failed: {str(e)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soccerpredictor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
