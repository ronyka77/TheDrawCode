model:
  name: bert_classifier
  version: "2.1.0"
  experiment_name: bert_experiment
  cpu_config:
    device: cpu
    fp16: False
    fp16_opt_level: O1
    max_grad_norm: 1.0
    num_workers: 4
  logging:
    log_dir: logs/bert
    metrics_tracking:
      - precision
      - recall
      - f1_score
      - auc
      - average_precision
      - brier_score
  params:
    model_type: bert
    model_name: bert-base-uncased
    num_labels: 2
    problem_type: single_label_classification
    hidden_dropout_prob: 0.1
    attention_probs_dropout_prob: 0.1
    max_seq_length: 256
    per_device_train_batch_size: 16
    gradient_accumulation_steps: 4
    num_train_epochs: 3
    warmup_ratio: 0.1
    weight_decay: 0.01
    learning_rate: 2e-5
    optim: adamw_torch
    lr_scheduler_type: linear
    max_grad_norm: 1.0
    early_stopping_patience: 3
    early_stopping_threshold: 0.01
    evaluation_strategy: steps
    save_strategy: steps
    metric_for_best_model: precision
    greater_is_better: true
    load_best_model_at_end: true
    device: cpu
    dataloader_num_workers: 0
    gradient_checkpointing: false
    group_by_length: true
    fp16: false
    bf16: false
    disable_tqdm: true
    report_to: none
    remove_unused_columns: false 